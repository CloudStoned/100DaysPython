<!doctype html><html lang="en"><head><title data-rh="true">Sign Language Recognition with Advanced Computer Vision | by Mihir Garimella | Towards Data Science</title><meta data-rh="true" charset="utf-8"/><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1,maximum-scale=1"/><meta data-rh="true" name="theme-color" content="#000000"/><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"/><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"/><meta data-rh="true" property="al:ios:app_name" content="Medium"/><meta data-rh="true" property="al:ios:app_store_id" content="828256236"/><meta data-rh="true" property="al:android:package" content="com.medium.reader"/><meta data-rh="true" property="fb:app_id" content="542599432471018"/><meta data-rh="true" property="og:site_name" content="Medium"/><meta data-rh="true" property="og:type" content="article"/><meta data-rh="true" property="article:published_time" content="2022-08-23T15:36:14.716Z"/><meta data-rh="true" name="title" content="Sign Language Recognition with Advanced Computer Vision | by Mihir Garimella | Towards Data Science"/><meta data-rh="true" property="og:title" content="Sign Language Recognition with Advanced Computer Vision"/><meta data-rh="true" property="al:android:url" content="medium://p/7b74f20f3442"/><meta data-rh="true" property="al:ios:url" content="medium://p/7b74f20f3442"/><meta data-rh="true" property="al:android:app_name" content="Medium"/><meta data-rh="true" name="description" content="Sign Language is a form of communication used primarily by people hard of hearing or deaf. This type of gesture-based language allows people to convey ideas and thoughts easily overcoming the…"/><meta data-rh="true" property="og:description" content="Detecting Sign Language Characters in Real Time Using MediaPipe and Keras"/><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442"/><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442"/><meta data-rh="true" property="og:image" content="https://miro.medium.com/v2/resize:fit:337/0*6aEBXcTf3YxIOund.png"/><meta data-rh="true" property="article:author" content="https://medium.com/@mihirg343"/><meta data-rh="true" name="author" content="Mihir Garimella"/><meta data-rh="true" name="robots" content="index,follow,max-image-preview:large"/><meta data-rh="true" name="referrer" content="unsafe-url"/><meta data-rh="true" property="twitter:title" content="Sign Language Recognition with Advanced Computer Vision"/><meta data-rh="true" name="twitter:site" content="@TDataScience"/><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/7b74f20f3442"/><meta data-rh="true" property="twitter:description" content="Detecting Sign Language Characters in Real Time Using MediaPipe and Keras"/><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/v2/resize:fit:337/0*6aEBXcTf3YxIOund.png"/><meta data-rh="true" name="twitter:card" content="summary_large_image"/><meta data-rh="true" name="twitter:label1" content="Reading time"/><meta data-rh="true" name="twitter:data1" content="8 min read"/><link data-rh="true" rel="icon" href="https://miro.medium.com/v2/resize:fill:256:256/1*VzTUkfeGymHP4Bvav-T-lA.png"/><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="/osd.xml"/><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://miro.medium.com/v2/resize:fill:152:152/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://miro.medium.com/v2/resize:fill:120:120/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://miro.medium.com/v2/resize:fill:76:76/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://miro.medium.com/v2/resize:fill:60:60/1*sHhtYhaCe2Uc3IU0IgKwIQ.png"/><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/Medium-Avatar-500x500.svg" color="#171717"/><link data-rh="true" rel="preconnect" href="https://glyph.medium.com" crossOrigin=""/><link data-rh="true" id="glyph_preload_link" rel="preload" as="style" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="https://glyph.medium.com/css/unbound.css"/><link data-rh="true" rel="author" href="https://medium.com/@mihirg343"/><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/sign-language-recognition-with-advanced-computer-vision-7b74f20f3442"/><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/7b74f20f3442"/><script data-rh="true" type="application/ld+json">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:1200\u002F0*6aEBXcTf3YxIOund.png"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442","dateCreated":"2022-08-23T15:36:14.716Z","datePublished":"2022-08-23T15:36:14.716Z","dateModified":"2022-12-04T17:19:59.795Z","headline":"Sign Language Recognition with Advanced Computer Vision","name":"Sign Language Recognition with Advanced Computer Vision","description":"Sign Language is a form of communication used primarily by people hard of hearing or deaf. This type of gesture-based language allows people to convey ideas and thoughts easily overcoming the…","identifier":"7b74f20f3442","author":{"@type":"Person","name":"Mihir Garimella","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@mihirg343"},"creator":["Mihir Garimella"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":192,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fv2\u002Fresize:fit:384\u002F1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442"}</script><style type="text/css" data-fela-rehydration="496" data-fela-type="STATIC">html{box-sizing:border-box;-webkit-text-size-adjust:100%}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}:root{--reach-tabs:1;--reach-menu-button:1}#speechify-root{font-family:Sohne, sans-serif}div[data-popper-reference-hidden="true"]{visibility:hidden;pointer-events:none}.grecaptcha-badge{visibility:hidden}
/*XCode style (c) Angel Garcia <angelgarcia.mail@gmail.com>*/.hljs {background: #fff;color: black;
}/* Gray DOCTYPE selectors like WebKit */
.xml .hljs-meta {color: #c0c0c0;
}.hljs-comment,
.hljs-quote {color: #007400;
}.hljs-tag,
.hljs-attribute,
.hljs-keyword,
.hljs-selector-tag,
.hljs-literal,
.hljs-name {color: #aa0d91;
}.hljs-variable,
.hljs-template-variable {color: #3F6E74;
}.hljs-code,
.hljs-string,
.hljs-meta .hljs-string {color: #c41a16;
}.hljs-regexp,
.hljs-link {color: #0E0EFF;
}.hljs-title,
.hljs-symbol,
.hljs-bullet,
.hljs-number {color: #1c00cf;
}.hljs-section,
.hljs-meta {color: #643820;
}.hljs-title.class_,
.hljs-class .hljs-title,
.hljs-type,
.hljs-built_in,
.hljs-params {color: #5c2699;
}.hljs-attr {color: #836C28;
}.hljs-subst {color: #000;
}.hljs-formula {background-color: #eee;font-style: italic;
}.hljs-addition {background-color: #baeeba;
}.hljs-deletion {background-color: #ffc8bd;
}.hljs-selector-id,
.hljs-selector-class {color: #9b703f;
}.hljs-doctag,
.hljs-strong {font-weight: bold;
}.hljs-emphasis {font-style: italic;
}
</style><style type="text/css" data-fela-rehydration="496" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@-moz-keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}@keyframes k1{0%{opacity:0.8}50%{opacity:0.5}100%{opacity:0.8}}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{display:block}.m{position:sticky}.n{top:0}.o{z-index:500}.p{padding:0 24px}.q{align-items:center}.r{border-bottom:solid 1px #F2F2F2}.y{height:41px}.z{line-height:20px}.ab{display:flex}.ac{height:57px}.ae{flex:1 0 auto}.af{color:inherit}.ag{fill:inherit}.ah{font-size:inherit}.ai{border:inherit}.aj{font-family:inherit}.ak{letter-spacing:inherit}.al{font-weight:inherit}.am{padding:0}.an{margin:0}.ao{cursor:pointer}.ap:disabled{cursor:not-allowed}.aq:disabled{color:#6B6B6B}.ar:disabled{fill:#6B6B6B}.au path{fill:#242424}.av{height:27px}.aw{margin-left:16px}.ax{border:none}.ay{border-radius:20px}.az{width:240px}.ba{background:#F9F9F9}.bb path{fill:#6B6B6B}.bd{outline:none}.be{font-family:sohne, "Helvetica Neue", Helvetica, Arial, sans-serif}.bf{font-size:14px}.bg{width:100%}.bh{padding:10px 20px 10px 0}.bi{background-color:transparent}.bj{color:#242424}.bk::placeholder{color:#6B6B6B}.bl{display:inline-block}.bm{margin-left:12px}.bn{margin-right:12px}.bo{border-radius:4px}.bp{margin-left:24px}.bq{height:24px}.bw{background-color:#F9F9F9}.bx{border-radius:50%}.by{height:32px}.bz{width:32px}.ca{justify-content:center}.cg{max-width:680px}.ch{min-width:0}.ci{animation:k1 1.2s ease-in-out infinite}.cj{height:100vh}.ck{margin-bottom:16px}.cl{margin-top:48px}.cm{align-items:flex-start}.cn{flex-direction:column}.co{justify-content:space-between}.cp{margin-bottom:24px}.cv{width:80%}.cw{background-color:#F2F2F2}.dc{height:44px}.dd{width:44px}.de{margin:auto 0}.df{margin-bottom:4px}.dg{height:16px}.dh{width:120px}.di{width:80px}.do{margin-bottom:8px}.dp{width:96%}.dq{width:98%}.dr{width:81%}.ds{margin-left:8px}.dt{color:#6B6B6B}.du{font-size:13px}.dv{height:100%}.eo{color:#FFFFFF}.ep{fill:#FFFFFF}.eq{background:rgba(102, 138, 170, 1)}.er{border-color:rgba(102, 138, 170, 1)}.ev:disabled{cursor:inherit !important}.ew:disabled{opacity:0.3}.ex:disabled:hover{background:rgba(102, 138, 170, 1)}.ey:disabled:hover{border-color:rgba(102, 138, 170, 1)}.ez{border-radius:99em}.fa{border-width:1px}.fb{border-style:solid}.fc{box-sizing:border-box}.fd{text-decoration:none}.fe{text-align:center}.fh{margin-right:32px}.fi{position:relative}.fj{fill:#6B6B6B}.fm{background:transparent}.fn svg{margin-left:4px}.fo svg{fill:#6B6B6B}.fq{box-shadow:inset 0 0 0 1px rgba(0, 0, 0, 0.05)}.fr{position:absolute}.fy{margin:0 24px}.gc{background:rgba(255, 255, 255, 1)}.gd{border:1px solid #F2F2F2}.ge{box-shadow:0 1px 4px #F2F2F2}.gf{max-height:100vh}.gg{overflow-y:auto}.gh{left:0}.gi{top:calc(100vh + 100px)}.gj{bottom:calc(100vh + 100px)}.gk{width:10px}.gl{pointer-events:none}.gm{word-break:break-word}.gn{word-wrap:break-word}.go:after{display:block}.gp:after{content:""}.gq:after{clear:both}.gr{line-height:1.23}.gs{letter-spacing:0}.gt{font-style:normal}.gu{font-weight:700}.hp{margin-bottom:-0.27em}.hq{line-height:1.394}.il{align-items:baseline}.im{width:48px}.in{height:48px}.io{border:2px solid rgba(255, 255, 255, 1)}.ip{z-index:0}.iq{box-shadow:none}.ir{border:1px solid rgba(0, 0, 0, 0.05)}.is{margin-left:-12px}.it{width:28px}.iu{height:28px}.iv{z-index:1}.iw{width:24px}.ix{margin-bottom:2px}.iy{flex-wrap:nowrap}.iz{font-size:16px}.ja{line-height:24px}.jc{margin:0 8px}.jd{display:inline}.je{color:rgba(102, 138, 170, 1)}.jf{fill:rgba(102, 138, 170, 1)}.ji{flex:0 0 auto}.jl{flex-wrap:wrap}.jo{white-space:pre-wrap}.jp{margin-right:4px}.jq{overflow:hidden}.jr{max-height:20px}.js{text-overflow:ellipsis}.jt{display:-webkit-box}.ju{-webkit-line-clamp:1}.jv{-webkit-box-orient:vertical}.jw{word-break:break-all}.jy{padding-left:8px}.jz{padding-right:8px}.la> *{flex-shrink:0}.lb{overflow-x:scroll}.lc::-webkit-scrollbar{display:none}.ld{scrollbar-width:none}.le{-ms-overflow-style:none}.lf{width:74px}.lg{flex-direction:row}.lh{z-index:2}.lk{-webkit-user-select:none}.ll{border:0}.lm{fill:rgba(117, 117, 117, 1)}.lp{outline:0}.lq{user-select:none}.lr> svg{pointer-events:none}.ma{cursor:progress}.mb{margin-left:4px}.mc{margin-top:0px}.md{opacity:1}.me{padding:4px 0}.mh{width:16px}.mj{display:inline-flex}.mp{max-width:100%}.mq{padding:8px 2px}.mr svg{color:#6B6B6B}.ni{margin-left:auto}.nj{margin-right:auto}.nk{max-width:721px}.nq{clear:both}.ns{cursor:zoom-in}.nt{z-index:auto}.nv{height:auto}.nw{margin-top:10px}.nx{max-width:728px}.oa{line-height:1.58}.ob{letter-spacing:-0.004em}.oc{font-family:source-serif-pro, Georgia, Cambria, "Times New Roman", Times, serif}.ov{margin-bottom:-0.46em}.ow{margin-top:32px}.ox{margin-bottom:14px}.oy{padding-top:24px}.oz{padding-bottom:10px}.pa{background-color:#000000}.pb{height:3px}.pc{width:3px}.pd{margin-right:20px}.pe{font-style:italic}.pf{text-decoration:underline}.pg{max-width:665px}.ph{margin:auto}.pi{padding-bottom:100%}.pj{height:0}.pk{max-width:337px}.pl{max-width:500px}.pm{max-width:450px}.pn{max-width:387px}.po{margin-bottom:26px}.pp{margin-top:6px}.pq{margin-top:8px}.pr{margin-right:8px}.ps{padding:8px 16px}.pt{border-radius:100px}.pu{transition:background 300ms ease}.pw{white-space:nowrap}.px{border-top:none}.qd{height:52px}.qe{max-height:52px}.qf{box-sizing:content-box}.qg{position:static}.qi{max-width:155px}.qt{align-items:flex-end}.qu{width:76px}.qv{height:76px}.qw{border:2px solid #F9F9F9}.qx{height:72px}.qy{width:72px}.qz{margin-left:-16px}.ra{width:36px}.rb{height:36px}.rc{width:auto}.rd{stroke:#F2F2F2}.re{color:#F2F2F2}.rf{fill:#F2F2F2}.rg{background:#F2F2F2}.rh{border-color:#F2F2F2}.rn{font-weight:500}.ro{font-size:24px}.rp{line-height:30px}.rq{letter-spacing:-0.016em}.rr{margin-top:16px}.rs{height:0px}.rt{border-bottom:solid 1px #E5E5E5}.rz{margin-top:72px}.sa{padding:24px 0}.sb{margin-bottom:0px}.sc{margin-right:16px}.as:hover:not(:disabled){color:rgba(25, 25, 25, 1)}.at:hover:not(:disabled){fill:rgba(25, 25, 25, 1)}.es:hover{background:rgba(90, 118, 144, 1)}.et:hover{border-color:rgba(90, 118, 144, 1)}.eu:hover{cursor:pointer}.fk:hover{color:#242424}.fl:hover{fill:#242424}.fp:hover svg{fill:#242424}.fs:hover{background-color:rgba(0, 0, 0, 0.1)}.jb:hover{text-decoration:underline}.jg:hover:not(:disabled){color:rgba(90, 118, 144, 1)}.jh:hover:not(:disabled){fill:rgba(90, 118, 144, 1)}.lo:hover{fill:rgba(8, 8, 8, 1)}.mf:hover{fill:#000000}.mg:hover p{color:#000000}.mi:hover{color:#000000}.ms:hover svg{color:#000000}.pv:hover{background-color:#F2F2F2}.ri:hover{background:#F2F2F2}.rj:hover{border-color:#F2F2F2}.rk:hover{cursor:wait}.rl:hover{color:#F2F2F2}.rm:hover{fill:#F2F2F2}.bc:focus-within path{fill:#242424}.ln:focus{fill:rgba(8, 8, 8, 1)}.mt:focus svg{color:#000000}.nu:focus{transform:scale(1.01)}.ls:active{border-style:none}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.bv{width:64px}.cf{margin:0 64px}.cu{height:48px}.db{margin-bottom:52px}.dn{margin-bottom:48px}.ee{font-size:14px}.ef{line-height:20px}.el{font-size:13px}.em{padding:5px 12px}.fg{display:flex}.fx{margin-bottom:68px}.gb{max-width:680px}.hl{font-size:42px}.hm{margin-top:1.19em}.hn{line-height:52px}.ho{letter-spacing:-0.011em}.id{font-size:22px}.ie{margin-top:0.92em}.if{line-height:28px}.ik{align-items:center}.km{border-top:solid 1px #F2F2F2}.kn{border-bottom:solid 1px #F2F2F2}.ko{margin:32px 0 0}.kp{padding:3px 8px}.ky> *{margin-right:24px}.kz> :last-child{margin-right:0}.lz{margin-top:0px}.mo{margin:0}.np{margin-top:56px}.or{font-size:20px}.os{margin-top:2.14em}.ot{line-height:32px}.ou{letter-spacing:-0.003em}.qc{margin-bottom:88px}.qn{display:inline-block}.qs{padding-top:72px}.ry{margin-top:40px}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.ly{margin-top:0px}.ny{margin-left:auto}.nz{text-align:center}.qm{display:inline-block}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.lx{margin-top:0px}.ql{display:inline-block}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.lv{margin-top:0px}.lw{margin-right:0px}.qk{display:inline-block}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.s{display:flex}.t{justify-content:space-between}.br{width:24px}.cb{margin:0 24px}.cq{height:40px}.cx{margin-bottom:44px}.dj{margin-bottom:32px}.dw{font-size:13px}.dx{line-height:20px}.eg{padding:0px 8px 1px}.ft{margin-bottom:4px}.gv{font-size:32px}.gw{margin-top:1.01em}.gx{line-height:38px}.gy{letter-spacing:-0.014em}.hr{font-size:18px}.hs{margin-top:0.79em}.ht{line-height:24px}.ig{align-items:flex-start}.jj{flex-direction:column}.jm{margin-bottom:2px}.ka{margin:24px -24px 0}.kb{padding:0}.kq> *{margin-right:8px}.kr> :last-child{margin-right:24px}.li{margin-left:0px}.lt{margin-top:0px}.lu{margin-right:0px}.mk{margin:0}.mu{border:1px solid #F2F2F2}.mv{border-radius:99em}.mw{padding:0px 16px 0px 12px}.mx{height:38px}.my{align-items:center}.na svg{margin-right:8px}.nl{margin-top:40px}.od{margin-top:1.56em}.oe{line-height:28px}.of{letter-spacing:-0.003em}.py{margin-bottom:80px}.qj{display:inline-block}.qo{padding-top:48px}.ru{margin-top:32px}.mz:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.bu{width:64px}.ce{margin:0 64px}.ct{height:48px}.da{margin-bottom:52px}.dm{margin-bottom:48px}.ec{font-size:14px}.ed{line-height:20px}.ej{font-size:13px}.ek{padding:5px 12px}.ff{display:flex}.fw{margin-bottom:68px}.ga{max-width:680px}.hh{font-size:42px}.hi{margin-top:1.19em}.hj{line-height:52px}.hk{letter-spacing:-0.011em}.ia{font-size:22px}.ib{margin-top:0.92em}.ic{line-height:28px}.ij{align-items:center}.ki{border-top:solid 1px #F2F2F2}.kj{border-bottom:solid 1px #F2F2F2}.kk{margin:32px 0 0}.kl{padding:3px 8px}.kw> *{margin-right:24px}.kx> :last-child{margin-right:0}.mn{margin:0}.no{margin-top:56px}.on{font-size:20px}.oo{margin-top:2.14em}.op{line-height:32px}.oq{letter-spacing:-0.003em}.qb{margin-bottom:88px}.qr{padding-top:72px}.rx{margin-top:40px}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.w{display:flex}.x{justify-content:space-between}.bt{width:64px}.cd{margin:0 48px}.cs{height:48px}.cz{margin-bottom:52px}.dl{margin-bottom:48px}.ea{font-size:13px}.eb{line-height:20px}.ei{padding:0px 8px 1px}.fv{margin-bottom:68px}.fz{max-width:680px}.hd{font-size:42px}.he{margin-top:1.19em}.hf{line-height:52px}.hg{letter-spacing:-0.011em}.hx{font-size:22px}.hy{margin-top:0.92em}.hz{line-height:28px}.ii{align-items:center}.ke{border-top:solid 1px #F2F2F2}.kf{border-bottom:solid 1px #F2F2F2}.kg{margin:32px 0 0}.kh{padding:3px 8px}.ku> *{margin-right:24px}.kv> :last-child{margin-right:0}.mm{margin:0}.nn{margin-top:56px}.oj{font-size:20px}.ok{margin-top:2.14em}.ol{line-height:32px}.om{letter-spacing:-0.003em}.qa{margin-bottom:88px}.qq{padding-top:72px}.rw{margin-top:40px}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.u{display:flex}.v{justify-content:space-between}.bs{width:24px}.cc{margin:0 24px}.cr{height:40px}.cy{margin-bottom:44px}.dk{margin-bottom:32px}.dy{font-size:13px}.dz{line-height:20px}.eh{padding:0px 8px 1px}.fu{margin-bottom:4px}.gz{font-size:32px}.ha{margin-top:1.01em}.hb{line-height:38px}.hc{letter-spacing:-0.014em}.hu{font-size:18px}.hv{margin-top:0.79em}.hw{line-height:24px}.ih{align-items:flex-start}.jk{flex-direction:column}.jn{margin-bottom:2px}.kc{margin:24px 0 0}.kd{padding:0}.ks> *{margin-right:8px}.kt> :last-child{margin-right:8px}.lj{margin-left:0px}.ml{margin:0}.nb{border:1px solid #F2F2F2}.nc{border-radius:99em}.nd{padding:0px 16px 0px 12px}.ne{height:38px}.nf{align-items:center}.nh svg{margin-right:8px}.nm{margin-top:40px}.og{margin-top:1.56em}.oh{line-height:28px}.oi{letter-spacing:-0.003em}.pz{margin-bottom:80px}.qp{padding-top:48px}.rv{margin-top:32px}.ng:hover{border-color:#E5E5E5}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="print">.qh{display:none}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="(orientation: landscape) and (max-width: 903.98px)">.jx{max-height:none}</style><style type="text/css" data-fela-rehydration="496" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.nr{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}</style></head><body><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><div class="l c"><div class="l m n o c"><div class="p q r s t u v w x i d y z"><a class="dt ag du be ak b am an ao ap aq ar as at s u w i d q dv z" href="https://rsci.app.link/?%24canonical_url=https%3A%2F%2Fmedium.com%2Fp%2F7b74f20f3442&amp;%7Efeature=LoOpenInAppButton&amp;%7Echannel=ShowPostUnderCollection&amp;source=---two_column_layout_nav----------------------------------" rel="noopener follow">Open in app<svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" fill="none" viewBox="0 0 10 10" class="ds"><path fill="currentColor" d="M.985 8.485a.375.375 0 1 0 .53.53zM8.75 1.25h.375A.375.375 0 0 0 8.75.875zM8.375 6.5a.375.375 0 1 0 .75 0zM3.5.875a.375.375 0 1 0 0 .75zm-1.985 8.14 7.5-7.5-.53-.53-7.5 7.5zm6.86-7.765V6.5h.75V1.25zM3.5 1.625h5.25v-.75H3.5z"></path></svg></a><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="p q r ab ac"><div class="ab q ae"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab" aria-label="Homepage" data-testid="headerMediumLogo" href="https://medium.com/?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="120" height="26" fill="none" viewBox="0 0 120 26" class="au av"><path fill="#000" d="m29.57 1.404.036-.008V1.12h-7.27l-6.75 15.979-6.75-15.98H1.003v.278l.035.008c1.327.302 2 .752 2 2.374v18.993c0 1.623-.676 2.073-2.003 2.374L1 25.153v.279h5.315v-.278l-.035-.008c-1.327-.302-2-.751-2-2.374V4.88l8.67 20.552h.492l8.924-21.125V23.24c-.114 1.282-.782 1.677-1.983 1.95l-.036.009v.275h9.259V25.2l-.036-.008c-1.203-.274-1.886-.67-2-1.95l-.006-19.464h.006c0-1.622.674-2.072 2-2.374m4.23 12.582c.15-3.412 1.367-5.875 3.41-5.918.629.01 1.157.219 1.568.62.872.852 1.282 2.634 1.219 5.298zm-.092.962h10.85v-.046c-.03-2.61-.78-4.64-2.228-6.033-1.25-1.204-3.103-1.867-5.048-1.867h-.043c-1.01 0-2.248.246-3.13.693a7.3 7.3 0 0 0-2.623 2.086c-1.185 1.479-1.903 3.477-2.078 5.724a14 14 0 0 0-.04.755q-.007.292-.001.587C29.484 21.934 32.213 26 37.059 26c4.254 0 6.73-3.132 7.348-7.336l-.312-.11c-1.085 2.259-3.034 3.628-5.252 3.461-3.028-.228-5.347-3.32-5.137-7.066m23.122 6.893c-.356.85-1.099 1.319-2.094 1.319s-1.905-.689-2.552-1.939c-.694-1.342-1.06-3.24-1.06-5.487 0-4.678 1.445-7.704 3.68-7.704.937 0 1.674.468 2.026 1.284zm7.198 3.335c-1.327-.316-2-.787-2-2.492V0l-8.062 2.392v.293l.05-.004c1.111-.09 1.866.064 2.304.472.343.32.51.809.51 1.498v3.11C56.033 7.25 55.088 7 53.94 7c-2.326 0-4.453.987-5.986 2.779-1.599 1.867-2.444 4.42-2.444 7.38 0 5.287 2.584 8.84 6.43 8.84 2.25 0 4.06-1.242 4.888-3.336v2.811h7.233v-.29zM70.94 3.085c0-1.65-1.236-2.896-2.875-2.896-1.632 0-2.908 1.272-2.908 2.896s1.278 2.896 2.908 2.896c1.64 0 2.875-1.245 2.875-2.896m1.903 22.092c-1.327-.316-2-.787-2-2.492h-.006V7.055l-7.234 2.092v.284l.043.004c1.566.14 1.994.683 1.994 2.525v13.515h7.24v-.29zm18.536 0c-1.327-.316-2-.787-2-2.492V7.055L82.49 9.078v.285l.04.004c1.28.136 1.65.71 1.65 2.56v9.88c-.426.85-1.227 1.356-2.196 1.39-1.573 0-2.439-1.07-2.439-3.012V7.055l-7.234 2.092v.284l.044.004c1.565.14 1.994.683 1.994 2.525v8.362a9.4 9.4 0 0 0 .15 1.741l.13.57C75.243 24.845 76.848 26 79.362 26c2.129 0 3.996-1.328 4.818-3.405v2.885h7.233v-.291zm28.102.298v-.291l-.035-.009c-1.44-.334-2.001-.964-2.001-2.248V12.295C117.445 8.98 115.597 7 112.5 7c-2.257 0-4.16 1.314-4.893 3.36-.582-2.168-2.257-3.36-4.734-3.36-2.175 0-3.88 1.156-4.612 3.11V7.056l-7.233 2.006v.286l.043.004c1.547.138 1.994.697 1.994 2.492v13.631h6.75v-.29l-.037-.01c-1.148-.271-1.519-.767-1.519-2.04V10.95c.304-.715.917-1.562 2.127-1.562 1.504 0 2.266 1.05 2.266 3.116v12.972h6.751v-.29l-.035-.01c-1.149-.271-1.52-.767-1.52-2.04V12.294a7 7 0 0 0-.095-1.21c.322-.777.97-1.696 2.23-1.696 1.524 0 2.265 1.02 2.265 3.116v12.972z"></path></svg></a><div class="aw h"><div class="ab ax ay az ba q bb bc"><div class="bl" aria-hidden="false" aria-describedby="searchResults" aria-labelledby="searchResults"></div><div class="bm bn ab"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div><input role="combobox" aria-controls="searchResults" aria-expanded="false" aria-label="search" data-testid="headerSearchInput" tabindex="0" class="ax bd be bf z bg bh bi bj bk" placeholder="Search" value=""/></div></div></div><div class="h k w ff fg"><div class="fh ab"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerWriteButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Fmedium.com%2Fnew-story&amp;source=---two_column_layout_nav-----------------------new_post_topnav-----------" rel="noopener follow"><div class="be b bf z dt fi fj ab q fk fl"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Write"><path fill="currentColor" d="M14 4a.5.5 0 0 0 0-1zm7 6a.5.5 0 0 0-1 0zm-7-7H4v1h10zM3 4v16h1V4zm1 17h16v-1H4zm17-1V10h-1v10zm-1 1a1 1 0 0 0 1-1h-1zM3 20a1 1 0 0 0 1 1v-1zM4 3a1 1 0 0 0-1 1h1z"></path><path stroke="currentColor" d="m17.5 4.5-8.458 8.458a.25.25 0 0 0-.06.098l-.824 2.47a.25.25 0 0 0 .316.316l2.47-.823a.25.25 0 0 0 .098-.06L19.5 6.5m-2-2 2.323-2.323a.25.25 0 0 1 .354 0l1.646 1.646a.25.25 0 0 1 0 .354L19.5 6.5m-2-2 2 2"></path></svg><div class="ds l">Write</div></div></a></span></div></div><div class="k j i d"><div class="fh ab"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSearchButton" href="https://medium.com/search?source=---two_column_layout_nav----------------------------------" rel="noopener follow"><div class="be b bf z dt fi fj ab q fk fl"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24" aria-label="Search"><path fill="currentColor" fill-rule="evenodd" d="M4.092 11.06a6.95 6.95 0 1 1 13.9 0 6.95 6.95 0 0 1-13.9 0m6.95-8.05a8.05 8.05 0 1 0 5.13 14.26l3.75 3.75a.56.56 0 1 0 .79-.79l-3.73-3.73A8.05 8.05 0 0 0 11.042 3z" clip-rule="evenodd"></path></svg></div></a></div></div><div class="fh h k j"><div class="ab q"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="be b dw dx eg dy dz eh ea eb ei ej ed ek el ef em eo ep eq er es et eu ev ew ex ey ez fa fb fc bl fd fe" data-testid="headerSignUpButton" href="https://medium.com/m/signin?operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign up</a></span></p><div class="aw l"><p class="be b dw dx dy dz ea eb ec ed ee ef dt"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerSignInButton" href="https://medium.com/m/signin?operation=login&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;source=post_page---two_column_layout_nav-----------------------global_nav-----------" rel="noopener follow">Sign in</a></span></p></div></div></div><div class="l" aria-hidden="false"><button class="ax fm am ab q ao fn fo fp" aria-label="user options menu" data-testid="headerUserIcon"><div class="l fi"><img alt="" class="l fc bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*dmbNkD5D-u45r44go_cf0g.png" width="32" height="32" loading="lazy" role="presentation"/><div class="fq bx l by bz fr n ax fs"></div></div></button></div></div></div><div class="l"><div class="ft fu fv fw fx l"><div class="ab ca"><div class="ch bg fy fz ga gb"></div></div><article><div class="l"><div class="l"><span class="l"></span><section><div><div class="fr gh gi gj gk gl"></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><div><h1 id="1070" class="pw-post-title gr gs gt be gu gv gw gx gy gz ha hb hc hd he hf hg hh hi hj hk hl hm hn ho hp bj" data-testid="storyTitle">Sign Language Recognition with Advanced Computer Vision</h1></div><div><h2 id="a5ac" class="pw-subtitle-paragraph hq gs gt be b hr hs ht hu hv hw hx hy hz ia ib ic id ie if cp dt">Detecting Sign Language Characters in Real Time Using MediaPipe and Keras</h2><div><div class="speechify-ignore ab co"><div class="speechify-ignore bg l"><div class="ig ih ii ij ik ab"><div><div class="ab il"><a href="https://medium.com/@mihirg343?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="l im in bx io ip"><div class="l fi"><img alt="Mihir Garimella" class="l fc bx dc dd cw" src="https://miro.medium.com/v2/resize:fill:88:88/1*FsTbICEiyEbhog5a_EbQkQ.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/><div class="iq bx l dc dd fr n ir fs"></div></div></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><div class="is ab fi"><div><div class="bl" aria-hidden="false"><div class="l it iu bx io iv"><div class="l fi"><img alt="Towards Data Science" class="l fc bx bq iw cw" src="https://miro.medium.com/v2/resize:fill:48:48/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="24" height="24" loading="lazy" data-testid="publicationPhoto"/><div class="iq bx l bq iw fr n ir fs"></div></div></div></div></div></div></a></div></div><div class="bm bg l"><div class="ab"><div style="flex:1"><span class="be b bf z bj"><div class="ix ab q"><div class="ab q iy"><div class="ab q"><div><div class="bl" aria-hidden="false"><p class="be b iz ja bj"><a class="af ag ah ai aj ak al am an ao ap aq ar jb" data-testid="authorName" href="https://medium.com/@mihirg343?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow">Mihir Garimella</a></p></div></div></div><span class="jc jd" aria-hidden="true"><span class="be b bf z dt">·</span></span><p class="be b iz ja dt"><span><a class="je jf ah ai aj ak al am an ao ap aq ar ew jg jh" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F46bbd28ad0a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=post_page-46bbd28ad0a----7b74f20f3442---------------------post_header-----------" rel="noopener follow">Follow</a></span></p></div></div></span></div></div><div class="l ji"><span class="be b bf z dt"><div class="ab cm jj jk jl"><div class="jm jn ab"><div class="be b bf z dt ab jo"><span class="jp l ji">Published in</span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jb ab q" data-testid="publicationName" href="https://towardsdatascience.com/?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b bf z jq jr js jt ju jv jw jx bj">Towards Data Science</p></a></div></div></div><div class="h k"><span class="jc jd" aria-hidden="true"><span class="be b bf z dt">·</span></span></div></div><span class="be b bf z dt"><div class="ab ae"><span data-testid="storyReadTime">8 min read</span><div class="jy jz l" aria-hidden="true"><span class="l" aria-hidden="true"><span class="be b bf z dt">·</span></span></div><span data-testid="storyPublishDate">Aug 23, 2022</span></div></span></div></span></div></div></div><div class="ab co ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp"><div class="h k w ff fg q"><div class="lf l"><div class="ab q lg lh"><div class="pw-multi-vote-icon fi jp li lj lk"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b74f20f3442&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=-----7b74f20f3442---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="ll ao lm ln lo lp am lq lr ls lk"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lt lu lv lw lx ly lz"><p class="be b du z dt"><span class="ma">--</span></p></div></div></div><div><div class="bl" aria-hidden="false"><button class="ao ll md me ab q fj mf mg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="mc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="be b du z dt"><span class="pw-responses-count mb mc">2</span></p></button></div></div></div><div class="ab q kq kr ks kt ku kv kw kx ky kz la lb lc ld le"><div class="mh k j i d"></div><div class="h k"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="headerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b74f20f3442&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;source=-----7b74f20f3442---------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dt mi" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="fc mj cm"><div class="l ae"><div class="ab ca"><div class="mk ml mm mn mo mp ch bg"><div class="ab"><div class="bl bg" aria-hidden="false"><div><div class="bl" aria-hidden="false"><button aria-label="Listen" data-testid="audioPlayButton" class="af fj ah ai aj ak al mq an ao ap ew mr ms mg mt mu mv mw mx s my mz na nb nc nd ne u nf ng nh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M3 12a9 9 0 1 1 18 0 9 9 0 0 1-18 0m9-10C6.477 2 2 6.477 2 12s4.477 10 10 10 10-4.477 10-10S17.523 2 12 2m3.376 10.416-4.599 3.066a.5.5 0 0 1-.777-.416V8.934a.5.5 0 0 1 .777-.416l4.599 3.066a.5.5 0 0 1 0 .832" clip-rule="evenodd"></path></svg><div class="j i d"><p class="be b bf z dt">Listen</p></div></button></div></div></div></div></div></div></div></div><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="headerSocialShareButton" class="af fj ah ai aj ak al mq an ao ap ew mr ms mg mt mu mv mw mx s my mz na nb nc nd ne u nf ng nh"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg><div class="j i d"><p class="be b bf z dt">Share</p></div></button></div></div></div></div></div></div></div></div></div><figure class="nl nm nn no np nq ni nj paragraph-image"><div role="button" tabindex="0" class="nr ns fi nt bg nu"><div class="ni nj nk"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*Iv-GIxB6KwJpZPaQ 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*Iv-GIxB6KwJpZPaQ 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*Iv-GIxB6KwJpZPaQ 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*Iv-GIxB6KwJpZPaQ 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*Iv-GIxB6KwJpZPaQ 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*Iv-GIxB6KwJpZPaQ 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Iv-GIxB6KwJpZPaQ 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*Iv-GIxB6KwJpZPaQ 640w, https://miro.medium.com/v2/resize:fit:720/0*Iv-GIxB6KwJpZPaQ 720w, https://miro.medium.com/v2/resize:fit:750/0*Iv-GIxB6KwJpZPaQ 750w, https://miro.medium.com/v2/resize:fit:786/0*Iv-GIxB6KwJpZPaQ 786w, https://miro.medium.com/v2/resize:fit:828/0*Iv-GIxB6KwJpZPaQ 828w, https://miro.medium.com/v2/resize:fit:1100/0*Iv-GIxB6KwJpZPaQ 1100w, https://miro.medium.com/v2/resize:fit:1400/0*Iv-GIxB6KwJpZPaQ 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mp nv c" width="700" height="467" loading="eager" role="presentation"/></picture></div></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Image of Sign Language ‘F’ from Pexels</figcaption></figure><p id="95d0" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Sign Language is a form of communication used primarily by people hard of hearing or deaf. This type of gesture-based language allows people to convey ideas and thoughts easily overcoming the barriers caused by difficulties from hearing issues.</p><p id="6412" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">A major issue with this convenient form of communication is the lack of knowledge of the language for the vast majority of the global population. Just as any other language, learning Sign Language takes much time and effort, discouraging to from being learned by the larger population.</p><p id="2444" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">However, an evident solution to this issue is present in the world of Machine Learning and Image Detection. Implementing predictive model technology to automatically classify Sign Language symbols can be used to create a form of real-time captioning for virtual conferences like Zoom meetings and other such things. This would greatly increase access of such services to those with hearing impairments as it would go hand-in-hand with voice-based captioning, creating a two-way communication system online for people with hearing issues.</p></div></div></div><div class="ab ca ow ox oy oz" role="separator"><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc"></span></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><p id="fe57" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Many large training datasets for Sign Language are available on Kaggle, a popular resource for data science. The one used in this model is called <strong class="oc gu"><em class="pe">“</em></strong><a class="af pf" href="https://www.kaggle.com/datasets/datamunge/sign-language-mnist" rel="noopener ugc nofollow" target="_blank"><strong class="oc gu"><em class="pe">Sign Language MNIST</em></strong></a><strong class="oc gu"><em class="pe">”</em></strong> and is a public-domain free-to-use dataset with pixel information for around 1,000 images of each of 24 ASL Letters, excluding J and Z as they are gesture-based signs.</p></div></div></div><div class="ab ca ow ox oy oz" role="separator"><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc"></span></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><figure class="nl nm nn no np nq ni nj paragraph-image"><div class="ni nj pg"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*EC2QFI9soQV-qMlY 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*EC2QFI9soQV-qMlY 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*EC2QFI9soQV-qMlY 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*EC2QFI9soQV-qMlY 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*EC2QFI9soQV-qMlY 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*EC2QFI9soQV-qMlY 1100w, https://miro.medium.com/v2/resize:fit:1330/format:webp/0*EC2QFI9soQV-qMlY 1330w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 665px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*EC2QFI9soQV-qMlY 640w, https://miro.medium.com/v2/resize:fit:720/0*EC2QFI9soQV-qMlY 720w, https://miro.medium.com/v2/resize:fit:750/0*EC2QFI9soQV-qMlY 750w, https://miro.medium.com/v2/resize:fit:786/0*EC2QFI9soQV-qMlY 786w, https://miro.medium.com/v2/resize:fit:828/0*EC2QFI9soQV-qMlY 828w, https://miro.medium.com/v2/resize:fit:1100/0*EC2QFI9soQV-qMlY 1100w, https://miro.medium.com/v2/resize:fit:1330/0*EC2QFI9soQV-qMlY 1330w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 665px"/><img alt="" class="bg mp nv c" width="665" height="471" loading="eager" role="presentation"/></picture></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">“Cropped image montage panel of various users and backgrounds for American Sign Language letters” from Sign Language MNIST</figcaption></figure><p id="a9e7" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The first step of preparing the data for training is to convert and shape all of the pixel data from the dataset into images so they can be read by the algorithm.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="bb1b" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The code above starts by reshaping all of the MNIST training image files so the model understands the input files. Along with this, the LabelBinarizer() variable takes the classes in the dataset and converts them to binary, a process that greatly speeds up the training of the model.</p><p id="ab32" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The next step is to create the data generator to randomly implement changes to the data, increasing the amount of training examples and making the images more realistic by adding noise and transformations to different instances.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="9d98" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">After processing the images, the CNN model must be compiled to recognize all of the classes of information being used in the data, namely the 24 different groups of images. Normalization of the data must also be added to the data, equally balancing the classes with less images.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="ff41" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Notice the initialization of the algorithm with the adding of variables such as the Conv2D model, and the condensing to 24 features. We also use batching techniques to allow the CNN to handle the data more efficiently.</p><p id="8e06" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Finally, defining the loss functions and metrics along with fitting the model to the data will create our Sign Language Recognition system. It is important to recognize the <strong class="oc gu"><em class="pe">model.save()</em></strong> command at the end of the statement due to the length of time required to build the model. Re-training the model for every use can take hours of time.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="6f2a" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">This code has a lot to unpack. Let’s look at it in sections.</p><p id="0b19" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj"><strong class="oc gu">Line 1:</strong></p><p id="de06" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The <strong class="oc gu"><em class="pe">model.compile()</em></strong> function takes many parameters, of which three are displayed in the code. The optimizer and loss parameters work together along with the epoch statement in the next line to efficiently reduce the amount of error in the model by incrementally changing computation methods on the data.</p><p id="57b5" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Along with this, the metric of choice to be optimized is the accuracy functions, which ensures that the model will have the maximum accuracy achievable after the set number of epochs.</p><p id="6506" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj"><strong class="oc gu">Line 4:</strong></p><p id="73ff" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The function run here fits the designed model to the data from the image data developed in the first bit of code. It also defines the number of <strong class="oc gu"><em class="pe">epochs </em></strong>or iterations the model has to enhance the accuracy of the image detection. The validation set is also called here, to introduce a testing aspect to the model. The model calculates the accuracy using this data.</p><p id="09c4" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj"><strong class="oc gu">Line 5:</strong></p><p id="89aa" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Of all of the statements in the code bit, the <strong class="oc gu"><em class="pe">model.save()</em></strong> function may be the most important part of this code, as it can potentially save hours of time when implementing the model.</p><figure class="nl nm nn no np nq ni nj paragraph-image"><div role="button" tabindex="0" class="nr ns fi nt bg nu"><div class="ni nj nk"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*yu75uOn-N8EFoXBd 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*yu75uOn-N8EFoXBd 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*yu75uOn-N8EFoXBd 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*yu75uOn-N8EFoXBd 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*yu75uOn-N8EFoXBd 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*yu75uOn-N8EFoXBd 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*yu75uOn-N8EFoXBd 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*yu75uOn-N8EFoXBd 640w, https://miro.medium.com/v2/resize:fit:720/0*yu75uOn-N8EFoXBd 720w, https://miro.medium.com/v2/resize:fit:750/0*yu75uOn-N8EFoXBd 750w, https://miro.medium.com/v2/resize:fit:786/0*yu75uOn-N8EFoXBd 786w, https://miro.medium.com/v2/resize:fit:828/0*yu75uOn-N8EFoXBd 828w, https://miro.medium.com/v2/resize:fit:1100/0*yu75uOn-N8EFoXBd 1100w, https://miro.medium.com/v2/resize:fit:1400/0*yu75uOn-N8EFoXBd 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mp nv c" width="700" height="467" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Image of Sign Language ‘X’ from Pexels</figcaption></figure><p id="572f" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The model developed accurately detects and classifies Sign Language symbols with about 95% training accuracy.</p></div></div></div><div class="ab ca ow ox oy oz" role="separator"><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc"></span></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><p id="4f45" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Now, using two popular live video processing libraries known as Mediapipe and Open-CV, we can take webcam input and run our previously developed model on real time video stream.</p><figure class="nl nm nn no np nq ni nj paragraph-image"><div role="button" tabindex="0" class="nr ns fi nt bg nu"><div class="ni nj nk"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*HN0e1ezZ5R5ifqpF 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*HN0e1ezZ5R5ifqpF 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*HN0e1ezZ5R5ifqpF 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*HN0e1ezZ5R5ifqpF 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*HN0e1ezZ5R5ifqpF 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*HN0e1ezZ5R5ifqpF 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*HN0e1ezZ5R5ifqpF 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*HN0e1ezZ5R5ifqpF 640w, https://miro.medium.com/v2/resize:fit:720/0*HN0e1ezZ5R5ifqpF 720w, https://miro.medium.com/v2/resize:fit:750/0*HN0e1ezZ5R5ifqpF 750w, https://miro.medium.com/v2/resize:fit:786/0*HN0e1ezZ5R5ifqpF 786w, https://miro.medium.com/v2/resize:fit:828/0*HN0e1ezZ5R5ifqpF 828w, https://miro.medium.com/v2/resize:fit:1100/0*HN0e1ezZ5R5ifqpF 1100w, https://miro.medium.com/v2/resize:fit:1400/0*HN0e1ezZ5R5ifqpF 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" class="bg mp nv c" width="700" height="467" loading="eager" role="presentation"/></picture></div></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Image of Woman Showing Sign Language from Pexels</figcaption></figure><p id="6720" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">To start, we need to import the required packages for the program.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="e7d3" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The OS command run at the beginning simply blocks unnecessary warnings from the Tensorflow library used by Mediapipe. This makes the future output provided by the program clearer to understand.</p><p id="62e6" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Before we initiate the main while loop of the code, we need to first define some variables such as the saved model and information on the camera for Open-CV.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="bc1f" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Each of the variables set here are grouped into one of four categories. The category at the beginning pertains directly to the model that we trained in the first part of this paper. The second and third sections of the code define variables required to run and start Mediapipe and Open-CV. The final category is used primarily to analyze the frame when detected, and create the dictionary used in the cross-referencing of the data provided by the image model.</p><p id="b796" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The next part to this program is the main while True loop in which much of the program runs in.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="d049" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">This section of the program takes the input from your camera and uses our imported image processing library to display the input from the device to the computer. This portion of code focuses on getting general information from your camera and simply showing it back in a new window. However, using the Mediapipe library, we can detect the major landmarks of the hand such as the fingers and palms, and create a bounding box around the hand.</p><figure class="nl nm nn no np nq ni nj paragraph-image"><div class="ni nj pk"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*6aEBXcTf3YxIOund.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*6aEBXcTf3YxIOund.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*6aEBXcTf3YxIOund.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*6aEBXcTf3YxIOund.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*6aEBXcTf3YxIOund.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*6aEBXcTf3YxIOund.png 1100w, https://miro.medium.com/v2/resize:fit:674/format:webp/0*6aEBXcTf3YxIOund.png 674w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 337px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*6aEBXcTf3YxIOund.png 640w, https://miro.medium.com/v2/resize:fit:720/0*6aEBXcTf3YxIOund.png 720w, https://miro.medium.com/v2/resize:fit:750/0*6aEBXcTf3YxIOund.png 750w, https://miro.medium.com/v2/resize:fit:786/0*6aEBXcTf3YxIOund.png 786w, https://miro.medium.com/v2/resize:fit:828/0*6aEBXcTf3YxIOund.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*6aEBXcTf3YxIOund.png 1100w, https://miro.medium.com/v2/resize:fit:674/0*6aEBXcTf3YxIOund.png 674w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 337px"/><img alt="" class="bg mp nv c" width="337" height="354" loading="lazy" role="presentation"/></picture></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Image of Hand Annotations from Mediapipe, by Author</figcaption></figure><p id="9599" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The idea of a bounding box is a crucial component to all forms of image classification and analysis. The box allows the model to focus directly on the portion of the image needed for the function. Without this, the algorithm finds patterns in wrong places and can cause an incorrect result.</p><p id="1d45" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">For instance, during the training process, the lack of a bounding box can lead to the model correlating features of an image such as a clock, or a chair, to a label. This may cause the program to notice the clock located in the image and decide what Sign Language character is being shown solely on the fact that a clock is present.</p><figure class="nl nm nn no np nq ni nj paragraph-image"><div class="ni nj pl"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*ngWT2fByrbzrHpkG.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*ngWT2fByrbzrHpkG.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*ngWT2fByrbzrHpkG.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*ngWT2fByrbzrHpkG.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*ngWT2fByrbzrHpkG.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*ngWT2fByrbzrHpkG.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1000/format:webp/0*ngWT2fByrbzrHpkG.jpeg 1000w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*ngWT2fByrbzrHpkG.jpeg 640w, https://miro.medium.com/v2/resize:fit:720/0*ngWT2fByrbzrHpkG.jpeg 720w, https://miro.medium.com/v2/resize:fit:750/0*ngWT2fByrbzrHpkG.jpeg 750w, https://miro.medium.com/v2/resize:fit:786/0*ngWT2fByrbzrHpkG.jpeg 786w, https://miro.medium.com/v2/resize:fit:828/0*ngWT2fByrbzrHpkG.jpeg 828w, https://miro.medium.com/v2/resize:fit:1100/0*ngWT2fByrbzrHpkG.jpeg 1100w, https://miro.medium.com/v2/resize:fit:1000/0*ngWT2fByrbzrHpkG.jpeg 1000w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px"/><img alt="" class="bg mp nv c" width="500" height="525" loading="lazy" role="presentation"/></picture></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Previous Image with a highlighted clock, by Author</figcaption></figure><p id="3ccf" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Almost done! The second to last part of the program is capturing a single frame on cue, cropping it to the dimensions of the bounding box.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="0b5b" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">This code looks very similar to the last portion of the program. This is due mainly to the fact that the process involving the production of the bounding box is the same in both parts. However, in this analysis section of the code, we make use of the image reshaping feature from Open-CV to resize the image to the dimensions of the bounding box, rather than creating a visual object around it. Along with this, we also use NumPy and Open-CV to modify the image to have the same characteristics as the images the model was trained on. We also use pandas to create a dataframe with the pixel data from the images saved, so we can normalize the data in the same way we did for the model creation.</p><figure class="nl nm nn no np nq ni nj paragraph-image"><div role="button" tabindex="0" class="nr ns fi nt bg nu"><div class="ni nj pm"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*S0zOudPJ2C6-GMny.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*S0zOudPJ2C6-GMny.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*S0zOudPJ2C6-GMny.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*S0zOudPJ2C6-GMny.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*S0zOudPJ2C6-GMny.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*S0zOudPJ2C6-GMny.png 1100w, https://miro.medium.com/v2/resize:fit:900/format:webp/0*S0zOudPJ2C6-GMny.png 900w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 450px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*S0zOudPJ2C6-GMny.png 640w, https://miro.medium.com/v2/resize:fit:720/0*S0zOudPJ2C6-GMny.png 720w, https://miro.medium.com/v2/resize:fit:750/0*S0zOudPJ2C6-GMny.png 750w, https://miro.medium.com/v2/resize:fit:786/0*S0zOudPJ2C6-GMny.png 786w, https://miro.medium.com/v2/resize:fit:828/0*S0zOudPJ2C6-GMny.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*S0zOudPJ2C6-GMny.png 1100w, https://miro.medium.com/v2/resize:fit:900/0*S0zOudPJ2C6-GMny.png 900w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 450px"/><img alt="" class="bg mp nv c" width="450" height="489" loading="lazy" role="presentation"/></picture></div></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Modified Image of Hand, by Author</figcaption></figure><p id="6528" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Towards the top of the code, you may notice the odd sequence of variables being defined. This is due to the nature of the camera library syntax. When an image is processed and changed by Open-CV, the changes are made on top of the frame used, essentially saving the changes made to the image. The definition of multiple variables of equal value makes it so that the frame displayed in by the function is separate from the picture on which the model is being ran on.</p><p id="733c" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Finally, we need to run the trained model on the processed image and process the information output.</p><figure class="nl nm nn no np nq"><div class="ph jq l fi"><div class="pi pj l"></div></div></figure><p id="2eca" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">There is a lot of information being run through this section of the code. We will dissect this part of the code one by one.</p><p id="e050" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The first two lines draw the predicted probabilities that a hand image is any of the different classes from Keras. The data is presented in the form of 2 tensors, of which, the first tensor contains information on the probabilities. A tensor is essentially a collection of feature vectors, very similar to an array. The tensor produced by the model is one dimensional, allowing it to be used with the linear algebra library NumPy to parse the information into a more pythonic form.</p><p id="e8af" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">From here, we utilize the previously created list of classes under the variable letterpred to create a dictionary, matching the values from the tensor to the keys. This allows us to match each character’s probability with the class it corresponds to.</p><p id="dfb5" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Following this step, we use list comprehension to order and sort the values from highest to lowest. This then allows us to take the first few items in the list and designate them the 3 characters that closest correspond to the Sign Language image shown.</p><p id="d25c" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">Finally, we use a for loop to cycle through all of the key:value pairs in the dictionary created to match the highest values to their corresponding keys and print out the output with each character’ probability.</p><figure class="nl nm nn no np nq ni nj paragraph-image"><div class="ni nj pl"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/0*IdEh9O6q4QpYi9va.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*IdEh9O6q4QpYi9va.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*IdEh9O6q4QpYi9va.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*IdEh9O6q4QpYi9va.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*IdEh9O6q4QpYi9va.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*IdEh9O6q4QpYi9va.png 1100w, https://miro.medium.com/v2/resize:fit:1000/format:webp/0*IdEh9O6q4QpYi9va.png 1000w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/0*IdEh9O6q4QpYi9va.png 640w, https://miro.medium.com/v2/resize:fit:720/0*IdEh9O6q4QpYi9va.png 720w, https://miro.medium.com/v2/resize:fit:750/0*IdEh9O6q4QpYi9va.png 750w, https://miro.medium.com/v2/resize:fit:786/0*IdEh9O6q4QpYi9va.png 786w, https://miro.medium.com/v2/resize:fit:828/0*IdEh9O6q4QpYi9va.png 828w, https://miro.medium.com/v2/resize:fit:1100/0*IdEh9O6q4QpYi9va.png 1100w, https://miro.medium.com/v2/resize:fit:1000/0*IdEh9O6q4QpYi9va.png 1000w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 500px"/><img alt="" class="bg mp nv c" width="500" height="514" loading="lazy" role="presentation"/></picture></div><figcaption class="nw fe nx ni nj ny nz be b bf z dt">Sign Language ‘A’, by Author</figcaption></figure><figure class="nl nm nn no np nq ni nj paragraph-image"><div class="ni nj pn"><picture><source srcSet="https://miro.medium.com/v2/resize:fit:640/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 1100w, https://miro.medium.com/v2/resize:fit:774/format:webp/1*0yoN0UZXpkeukPIC3_rXlQ.png 774w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 387px" type="image/webp"/><source data-testid="og" srcSet="https://miro.medium.com/v2/resize:fit:640/1*0yoN0UZXpkeukPIC3_rXlQ.png 640w, https://miro.medium.com/v2/resize:fit:720/1*0yoN0UZXpkeukPIC3_rXlQ.png 720w, https://miro.medium.com/v2/resize:fit:750/1*0yoN0UZXpkeukPIC3_rXlQ.png 750w, https://miro.medium.com/v2/resize:fit:786/1*0yoN0UZXpkeukPIC3_rXlQ.png 786w, https://miro.medium.com/v2/resize:fit:828/1*0yoN0UZXpkeukPIC3_rXlQ.png 828w, https://miro.medium.com/v2/resize:fit:1100/1*0yoN0UZXpkeukPIC3_rXlQ.png 1100w, https://miro.medium.com/v2/resize:fit:774/1*0yoN0UZXpkeukPIC3_rXlQ.png 774w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 387px"/><img alt="" class="bg mp nv c" width="387" height="130" loading="lazy" role="presentation"/></picture></div></figure><p id="940b" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">As shown, the model accurately predicts the character being shown from the camera. Along with the Predicted Character, the program also displays the confidence of the classification from the CNN Keras model.</p></div></div></div><div class="ab ca ow ox oy oz" role="separator"><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc pd"></span><span class="pa bx bl pb pc"></span></div><div class="gm gn go gp gq"><div class="ab ca"><div class="ch bg fy fz ga gb"><p id="ef69" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">The model developed can be implemented in various ways, with the main use being a captioning device for calls involving video communication like Facetime. To create such an application, the model would have to be running frame-by-frame, predicting what sign is being shown at all times. Using other systems, we can also recognize when an individual is showing no sign, or is transitioning between signs, to more accurately judge the words being shown through ASL. This implementation could be used to string together letters being shown to eventually recognize words and even sentences, creating a fully functioning Sign Language to text translator. Such a device would greatly increase ease-of-access to the benefits of virtual communication for those with hearing imparities.</p><p id="052c" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj">This program allows for simple and easy communication from Sign Language to English through the use of Keras image analysis models. The code for this project can be found on my GitHub profile, linked below:</p><p id="61bf" class="pw-post-body-paragraph oa ob gt oc b hr od oe of hu og oh oi oj ok ol om on oo op oq or os ot ou ov gm bj"><a class="af pf" href="https://github.com/mg343/Sign-Language-Detection" rel="noopener ugc nofollow" target="_blank"><strong class="oc gu"><em class="pe">mg343/Sign-Language-Detection (github.com)</em></strong></a></p></div></div></div></div></section></div></div></article></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="po pp ab jl"><div class="pq ab"><a class="pr ax am ao" href="https://medium.com/tag/nlp?source=post_page-----7b74f20f3442---------------nlp-----------------" rel="noopener follow"><div class="ps fi cw pt gd pu pv be b bf z bj pw">NLP</div></a></div><div class="pq ab"><a class="pr ax am ao" href="https://medium.com/tag/sign-language?source=post_page-----7b74f20f3442---------------sign_language-----------------" rel="noopener follow"><div class="ps fi cw pt gd pu pv be b bf z bj pw">Sign Language</div></a></div><div class="pq ab"><a class="pr ax am ao" href="https://medium.com/tag/machine-learning?source=post_page-----7b74f20f3442---------------machine_learning-----------------" rel="noopener follow"><div class="ps fi cw pt gd pu pv be b bf z bj pw">Machine Learning</div></a></div><div class="pq ab"><a class="pr ax am ao" href="https://medium.com/tag/keras?source=post_page-----7b74f20f3442---------------keras-----------------" rel="noopener follow"><div class="ps fi cw pt gd pu pv be b bf z bj pw">Keras</div></a></div><div class="pq ab"><a class="pr ax am ao" href="https://medium.com/tag/editors-pick?source=post_page-----7b74f20f3442---------------editors_pick-----------------" rel="noopener follow"><div class="ps fi cw pt gd pu pv be b bf z bj pw">Editors Pick</div></a></div></div></div></div><div class="l"></div><footer class="px py pz qa qb qc qd qe qf ab q qg iv c"><div class="l ae"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ab co qh"><div class="ab q lg"><div class="qi l"><span class="l qj qk ql e d"><div class="ab q lg lh"><div class="pw-multi-vote-icon fi jp li lj lk"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b74f20f3442&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=-----7b74f20f3442---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="ll ao lm ln lo lp am lq lr ls lk"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lt lu lv lw lx ly lz"><p class="be b du z dt"><span class="ma">--</span></p></div></div></span><span class="l h g f qm qn"><div class="ab q lg lh"><div class="pw-multi-vote-icon fi jp li lj lk"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerClapButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fvote%2Ftowards-data-science%2F7b74f20f3442&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=-----7b74f20f3442---------------------clap_footer-----------" rel="noopener follow"><div><div class="bl" aria-hidden="false"><div class="ll ao lm ln lo lp am lq lr ls lk"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" aria-label="clap"><path fill-rule="evenodd" d="M11.37.828 12 3.282l.63-2.454zM13.916 3.953l1.523-2.112-1.184-.39zM8.589 1.84l1.522 2.112-.337-2.501zM18.523 18.92c-.86.86-1.75 1.246-2.62 1.33a6 6 0 0 0 .407-.372c2.388-2.389 2.86-4.951 1.399-7.623l-.912-1.603-.79-1.672c-.26-.56-.194-.98.203-1.288a.7.7 0 0 1 .546-.132c.283.046.546.231.728.5l2.363 4.157c.976 1.624 1.141 4.237-1.324 6.702m-10.999-.438L3.37 14.328a.828.828 0 0 1 .585-1.408.83.83 0 0 1 .585.242l2.158 2.157a.365.365 0 0 0 .516-.516l-2.157-2.158-1.449-1.449a.826.826 0 0 1 1.167-1.17l3.438 3.44a.363.363 0 0 0 .516 0 .364.364 0 0 0 0-.516L5.293 9.513l-.97-.97a.826.826 0 0 1 0-1.166.84.84 0 0 1 1.167 0l.97.968 3.437 3.436a.36.36 0 0 0 .517 0 .366.366 0 0 0 0-.516L6.977 7.83a.82.82 0 0 1-.241-.584.82.82 0 0 1 .824-.826c.219 0 .43.087.584.242l5.787 5.787a.366.366 0 0 0 .587-.415l-1.117-2.363c-.26-.56-.194-.98.204-1.289a.7.7 0 0 1 .546-.132c.283.046.545.232.727.501l2.193 3.86c1.302 2.38.883 4.59-1.277 6.75-1.156 1.156-2.602 1.627-4.19 1.367-1.418-.236-2.866-1.033-4.079-2.246M10.75 5.971l2.12 2.12c-.41.502-.465 1.17-.128 1.89l.22.465-3.523-3.523a.8.8 0 0 1-.097-.368c0-.22.086-.428.241-.584a.847.847 0 0 1 1.167 0m7.355 1.705c-.31-.461-.746-.758-1.23-.837a1.44 1.44 0 0 0-1.11.275c-.312.24-.505.543-.59.881a1.74 1.74 0 0 0-.906-.465 1.47 1.47 0 0 0-.82.106l-2.182-2.182a1.56 1.56 0 0 0-2.2 0 1.54 1.54 0 0 0-.396.701 1.56 1.56 0 0 0-2.21-.01 1.55 1.55 0 0 0-.416.753c-.624-.624-1.649-.624-2.237-.037a1.557 1.557 0 0 0 0 2.2c-.239.1-.501.238-.715.453a1.56 1.56 0 0 0 0 2.2l.516.515a1.556 1.556 0 0 0-.753 2.615L7.01 19c1.32 1.319 2.909 2.189 4.475 2.449q.482.08.971.08c.85 0 1.653-.198 2.393-.579.231.033.46.054.686.054 1.266 0 2.457-.52 3.505-1.567 2.763-2.763 2.552-5.734 1.439-7.586z" clip-rule="evenodd"></path></svg></div></div></div></a></span></div><div class="pw-multi-vote-count l lt lu lv lw lx ly lz"><p class="be b du z dt"><span class="ma">--</span></p></div></div></span></div><div class="bp ab"><div><div class="bl" aria-hidden="false"><button class="ao ll md me ab q fj mf mg" aria-label="responses"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" class="mc"><path d="M18.006 16.803c1.533-1.456 2.234-3.325 2.234-5.321C20.24 7.357 16.709 4 12.191 4S4 7.357 4 11.482c0 4.126 3.674 7.482 8.191 7.482.817 0 1.622-.111 2.393-.327.231.2.48.391.744.559 1.06.693 2.203 1.044 3.399 1.044.224-.008.4-.112.486-.287a.49.49 0 0 0-.042-.518c-.495-.67-.845-1.364-1.04-2.057a4 4 0 0 1-.125-.598zm-3.122 1.055-.067-.223-.315.096a8 8 0 0 1-2.311.338c-4.023 0-7.292-2.955-7.292-6.587 0-3.633 3.269-6.588 7.292-6.588 4.014 0 7.112 2.958 7.112 6.593 0 1.794-.608 3.469-2.027 4.72l-.195.168v.255c0 .056 0 .151.016.295.025.231.081.478.154.733.154.558.398 1.117.722 1.659a5.3 5.3 0 0 1-2.165-.845c-.276-.176-.714-.383-.941-.59z"></path></svg><p class="be b bf z dt"><span class="pw-responses-count mb mc">2</span></p></button></div></div></div></div><div class="ab q"><div class="pd l ji"><div><div class="bl" aria-hidden="false"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" data-testid="footerBookmarkButton" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fbookmark%2Fp%2F7b74f20f3442&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;source=--------------------------bookmark_footer-----------" rel="noopener follow"><svg xmlns="http://www.w3.org/2000/svg" width="25" height="25" fill="none" viewBox="0 0 25 25" class="dt mi" aria-label="Add to list bookmark button"><path fill="currentColor" d="M18 2.5a.5.5 0 0 1 1 0V5h2.5a.5.5 0 0 1 0 1H19v2.5a.5.5 0 1 1-1 0V6h-2.5a.5.5 0 0 1 0-1H18zM7 7a1 1 0 0 1 1-1h3.5a.5.5 0 0 0 0-1H8a2 2 0 0 0-2 2v14a.5.5 0 0 0 .805.396L12.5 17l5.695 4.396A.5.5 0 0 0 19 21v-8.5a.5.5 0 0 0-1 0v7.485l-5.195-4.012a.5.5 0 0 0-.61 0L7 19.985z"></path></svg></a></span></div></div></div><div class="pd l ji"><div class="bl" aria-hidden="false" aria-describedby="postFooterSocialMenu" aria-labelledby="postFooterSocialMenu"><div><div class="bl" aria-hidden="false"><button aria-controls="postFooterSocialMenu" aria-expanded="false" aria-label="Share Post" data-testid="footerSocialShareButton" class="af fj ah ai aj ak al mq an ao ap ew mr ms mg mt"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" fill="none" viewBox="0 0 24 24"><path fill="currentColor" fill-rule="evenodd" d="M15.218 4.931a.4.4 0 0 1-.118.132l.012.006a.45.45 0 0 1-.292.074.5.5 0 0 1-.3-.13l-2.02-2.02v7.07c0 .28-.23.5-.5.5s-.5-.22-.5-.5v-7.04l-2 2a.45.45 0 0 1-.57.04h-.02a.4.4 0 0 1-.16-.3.4.4 0 0 1 .1-.32l2.8-2.8a.5.5 0 0 1 .7 0l2.8 2.79a.42.42 0 0 1 .068.498m-.106.138.008.004v-.01zM16 7.063h1.5a2 2 0 0 1 2 2v10a2 2 0 0 1-2 2h-11c-1.1 0-2-.9-2-2v-10a2 2 0 0 1 2-2H8a.5.5 0 0 1 .35.15.5.5 0 0 1 .15.35.5.5 0 0 1-.15.35.5.5 0 0 1-.35.15H6.4c-.5 0-.9.4-.9.9v10.2a.9.9 0 0 0 .9.9h11.2c.5 0 .9-.4.9-.9v-10.2c0-.5-.4-.9-.9-.9H16a.5.5 0 0 1 0-1" clip-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></footer><div class="qo qp qq qr qs l bw"><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="ck ab qt co"><div class="ab il"><a href="https://medium.com/@mihirg343?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><div class="l qu qv bx qw ip"><div class="l fi"><img alt="Mihir Garimella" class="l fc bx qx qy cw" src="https://miro.medium.com/v2/resize:fill:144:144/1*FsTbICEiyEbhog5a_EbQkQ.jpeg" width="72" height="72" loading="lazy"/><div class="iq bx l qx qy fr n ir fs"></div></div></div></a><a href="https://towardsdatascience.com/?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><div class="qz ab fi"><div><div class="bl" aria-hidden="false"><div class="l ra rb bx qw iv"><div class="l fi"><img alt="Towards Data Science" class="l fc bx by bz cw" src="https://miro.medium.com/v2/resize:fill:64:64/1*CJe3891yB1A1mzMdqemkdg.jpeg" width="32" height="32" loading="lazy"/><div class="iq bx l by bz fr n ir fs"></div></div></div></div></div></div></a></div><div class="j i d"><div class="ab"><span><a class="be b bf z eo ps ep eq er es et eu ev ew ex ey ez rc fa fb fc bl fd fe" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F46bbd28ad0a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=post_page-46bbd28ad0a----7b74f20f3442---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe54576fe18a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;newsletterV3=46bbd28ad0a&amp;newsletterV3Id=e54576fe18a&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=-----7b74f20f3442---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z re am rf rg rh ri rj rk rl rm ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none" viewBox="0 0 38 38" class="rd rb ra"><rect width="0.5" height="6.5" x="26.25" y="9.25" rx="0.25"></rect><rect width="0.5" height="6.5" x="29.75" y="12.25" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5 19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="ab cm co"><div class="l"><div class="ab q"><a class="af ag ah ai aj ak al am an ao ap aq ar as at ab q" href="https://medium.com/@mihirg343?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><h2 class="pw-author-name be rn ro rp rq bj"><span class="gm jz">Written by <!-- -->Mihir Garimella</span></h2></a></div><div class="pq ab"><div class="l ji"><span class="pw-follower-count be b bf z bj"><a class="af ag ah ai aj ak al am an ao ap aq ar jb" href="https://medium.com/@mihirg343/followers?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow">32 Followers</a></span></div><div class="be b bf z jq jr js ab ju jv jw jx dt jo"><span class="jc l" aria-hidden="true"><span class="be b bf z dt">·</span></span><span class="l ji">Writer for </span><div><div class="l" aria-hidden="false"><a class="af ag ah ai aj ak al am an ao ap aq ar jb ab q" href="https://towardsdatascience.com/?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b bf z jq jr js jt ju jv jw jx bj">Towards Data Science</p></a></div></div></div></div><div class="rr l"></div></div><div class="h k"><div class="ab"><span><a class="be b bf z eo ps ep eq er es et eu ev ew ex ey ez rc fa fb fc bl fd fe" href="https://medium.com/m/signin?actionUrl=https%3A%2F%2Fmedium.com%2F_%2Fsubscribe%2Fuser%2F46bbd28ad0a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=post_page-46bbd28ad0a----7b74f20f3442---------------------follow_profile-----------" rel="noopener follow">Follow</a></span><div class="ds l"><div><div><div class="bl" aria-hidden="false"><div class="l"><span><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/m/signin?actionUrl=%2F_%2Fapi%2Fsubscriptions%2Fnewsletters%2Fe54576fe18a&amp;operation=register&amp;redirect=https%3A%2F%2Ftowardsdatascience.com%2Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442&amp;newsletterV3=46bbd28ad0a&amp;newsletterV3Id=e54576fe18a&amp;user=Mihir+Garimella&amp;userId=46bbd28ad0a&amp;source=-----7b74f20f3442---------------------subscribe_user-----------" rel="noopener follow"><button class="be b bf z re am rf rg rh ri rj rk rl rm ev ew ex ey ez fa fb fc bl fd fe" aria-label="Subscribe"><svg xmlns="http://www.w3.org/2000/svg" width="38" height="38" fill="none" viewBox="0 0 38 38" class="rd rb ra"><rect width="0.5" height="6.5" x="26.25" y="9.25" rx="0.25"></rect><rect width="0.5" height="6.5" x="29.75" y="12.25" rx="0.25" transform="rotate(90 29.75 12.25)"></rect><path d="M19.5 12.5h-7a1 1 0 0 0-1 1v11a1 1 0 0 0 1 1h13a1 1 0 0 0 1-1v-5"></path><path d="M11.5 14.5 19 20l4-3"></path></svg></button></a></span></div></div></div></div></div></div></div></div><div class="rs bg rt ru rv rw rx ry"></div></div></div><div class="h k j"><div class="rs bg rt rz"></div><div class="ab ca"><div class="ch bg fy fz ga gb"><div class="sa ab lg jl"><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://help.medium.com/hc/en-us?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Help</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.statuspage.io/?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Status</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/about?autoplay=1&amp;source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">About</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/jobs-at-medium/work-at-medium-959d1a85284e?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Careers</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="pressinquiries@medium.com?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Press</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://blog.medium.com/?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Blog</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-privacy-policy-f03bf92035c9?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Privacy</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://policy.medium.com/medium-terms-of-service-9db0094a1e0f?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Terms</p></a></div><div class="sb sc l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://speechify.com/medium?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Text to speech</p></a></div><div class="sb l"><a class="af ag ah ai aj ak al am an ao ap aq ar as at" href="https://medium.com/business?source=post_page-----7b74f20f3442--------------------------------" rel="noopener follow"><p class="be b du z dt">Teams</p></a></div></div></div></div></div></div></div></div></div></div><script>window.__BUILD_ID__="main-20240802-160526-be1ec4e2e8"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"algolia":{"queries":{}},"cache":{"experimentGroupSet":true,"reason":"","group":"enabled","tags":["group-edgeCachePosts","post-7b74f20f3442","user-46bbd28ad0a","collection-7f60cf5620c9"],"serverVariantState":"44136fa355b3678a1146ad16f7e8649e94fb4fc21fe77e8310c060f61caaff8a","middlewareEnabled":true,"cacheStatus":"DYNAMIC","shouldUseCache":true,"vary":[],"lohpSummerUpsellEnabled":true,"logoUpdatePhase2Enabled":false},"client":{"hydrated":false,"isUs":false,"isNativeMedium":false,"isSafariMobile":false,"isSafari":false,"isFirefox":false,"routingEntity":{"type":"COLLECTION","id":"7f60cf5620c9","explicit":true},"viewerIsBot":false},"debug":{"requestId":"f743f5ab-fca2-4347-aeac-22843c05f59b","hybridDevServices":[],"originalSpanCarrier":{}},"multiVote":{"clapsPerPost":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":false},"hideGoogleOneTap":false,"hasRenderedAlternateUserBanner":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"","hasSetReferrer":false,"susiModal":{"step":null,"operation":"register"},"postRead":false,"partnerProgram":{"selectedCountryCode":null},"queryString":"","currentHash":""},"config":{"nodeEnv":"production","version":"main-20240802-160526-be1ec4e2e8","target":"production","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","recaptchaEnterpriseKeyId":"6Le-uGgpAAAAAPprRaokM8AKthQ9KNGdoxaGUvVp","datadog":{"applicationId":"6702d87d-a7e0-42fe-bbcb-95b469547ea0","clientToken":"pub853ea8d17ad6821d9f8f11861d23dfed","rumToken":"pubf9cc52896502b9413b68ba36fc0c7162","context":{"deployment":{"target":"production","tag":"main-20240802-160526-be1ec4e2e8","commit":"be1ec4e2e8683bb44334f1f451ad8bcddb523a3c"}},"datacenter":"us"},"googleAnalyticsCode":"G-7JY7T788PK","googlePay":{"apiVersion":"2","apiVersionMinor":"0","merchantId":"BCR2DN6TV7EMTGBM","merchantName":"Medium","instanceMerchantId":"13685562959212738550"},"applePay":{"version":3},"signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumMastodonDomainName":"me.dm","mediumOwnedAndOperatedCollectionIds":["8a9336e5bb4","b7e45b22fec3","193b68bd4fba","8d6b8a439e32","54c98c43354d","3f6ecf56618","d944778ce714","92d2092dc598","ae2a65f35510","1285ba81cada","544c7006046e","fc8964313712","40187e704f1c","88d9857e584e","7b6769f2748b","bcc38c8f6edf","cef6983b292","cb8577c9149e","444d13b52878","713d7dbc99b0","ef8e90590e66","191186aaafa0","55760f21cdc5","9dc80918cc93","bdc4052bbdba","8ccfed20cbb2"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"topicsToFollow":["d61cf867d93f","8a146bc21b28","1eca0103fff3","4d562ee63426","aef1078a3ef5","e15e46793f8d","6158eb913466","55f1c20aba7a","3d18b94f6858","4861fee224fd","63c6f1f93ee","1d98b3a9a871","decb52b64abf","ae5d4995e225","830cded25262"],"topicToTagMappings":{"accessibility":"accessibility","addiction":"addiction","android-development":"android-development","art":"art","artificial-intelligence":"artificial-intelligence","astrology":"astrology","basic-income":"basic-income","beauty":"beauty","biotech":"biotech","blockchain":"blockchain","books":"books","business":"business","cannabis":"cannabis","cities":"cities","climate-change":"climate-change","comics":"comics","coronavirus":"coronavirus","creativity":"creativity","cryptocurrency":"cryptocurrency","culture":"culture","cybersecurity":"cybersecurity","data-science":"data-science","design":"design","digital-life":"digital-life","disability":"disability","economy":"economy","education":"education","equality":"equality","family":"family","feminism":"feminism","fiction":"fiction","film":"film","fitness":"fitness","food":"food","freelancing":"freelancing","future":"future","gadgets":"gadgets","gaming":"gaming","gun-control":"gun-control","health":"health","history":"history","humor":"humor","immigration":"immigration","ios-development":"ios-development","javascript":"javascript","justice":"justice","language":"language","leadership":"leadership","lgbtqia":"lgbtqia","lifestyle":"lifestyle","machine-learning":"machine-learning","makers":"makers","marketing":"marketing","math":"math","media":"media","mental-health":"mental-health","mindfulness":"mindfulness","money":"money","music":"music","neuroscience":"neuroscience","nonfiction":"nonfiction","outdoors":"outdoors","parenting":"parenting","pets":"pets","philosophy":"philosophy","photography":"photography","podcasts":"podcast","poetry":"poetry","politics":"politics","privacy":"privacy","product-management":"product-management","productivity":"productivity","programming":"programming","psychedelics":"psychedelics","psychology":"psychology","race":"race","relationships":"relationships","religion":"religion","remote-work":"remote-work","san-francisco":"san-francisco","science":"science","self":"self","self-driving-cars":"self-driving-cars","sexuality":"sexuality","social-media":"social-media","society":"society","software-engineering":"software-engineering","space":"space","spirituality":"spirituality","sports":"sports","startups":"startup","style":"style","technology":"technology","transportation":"transportation","travel":"travel","true-crime":"true-crime","tv":"tv","ux":"ux","venture-capital":"venture-capital","visual-design":"visual-design","work":"work","world":"world","writing":"writing"},"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*kFrc4tBFM_tCis-2Ic87WA.png","height":810,"width":1440},"postPreviewImage":{"imageId":"1*hn4v1tCaJy7cWMyb0bpNpQ.png","height":386,"width":579}},"collectionStructuredData":{"8d6b8a439e32":{"name":"Elemental","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F980\u002F1*9ygdqoKprhwuTVKUM0DLPA@2x.png","width":980,"height":159}}},"3f6ecf56618":{"name":"Forge","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F596\u002F1*uULpIlImcO5TDuBZ6lm7Lg@2x.png","width":596,"height":183}}},"ae2a65f35510":{"name":"GEN","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F264\u002F1*RdVZMdvfV3YiZTw6mX7yWA.png","width":264,"height":140}}},"88d9857e584e":{"name":"LEVEL","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*JqYMhNX6KNNb2UlqGqO2WQ.png","width":540,"height":108}}},"7b6769f2748b":{"name":"Marker","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fcdn-images-1.medium.com\u002Fmax\u002F383\u002F1*haCUs0wF6TgOOvfoY-jEoQ@2x.png","width":383,"height":92}}},"444d13b52878":{"name":"OneZero","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*cw32fIqCbRWzwJaoQw6BUg.png","width":540,"height":123}}},"8ccfed20cbb2":{"name":"Zora","data":{"@type":"NewsMediaOrganization","ethicsPolicy":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Farticles\u002F360043290473","logo":{"@type":"ImageObject","url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F540\u002F1*tZUQqRcCCZDXjjiZ4bDvgQ.png","width":540,"height":106}}}},"embeddedPostIds":{"coronavirus":"cd3010f9d81f"},"sharedCdcMessaging":{"COVID_APPLICABLE_TAG_SLUGS":[],"COVID_APPLICABLE_TOPIC_NAMES":[],"COVID_APPLICABLE_TOPIC_NAMES_FOR_TOPIC_PAGE":[],"COVID_MESSAGES":{"tierA":{"text":"For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":66,"end":73,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"tierB":{"text":"Anyone can publish on Medium per our Policies, but we don’t fact-check every story. For more info about the coronavirus, see cdc.gov.","markups":[{"start":37,"end":45,"href":"https:\u002F\u002Fhelp.medium.com\u002Fhc\u002Fen-us\u002Fcategories\u002F201931128-Policies-Safety"},{"start":125,"end":132,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"paywall":{"text":"This article has been made free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":56,"end":70,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":138,"end":145,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]},"unbound":{"text":"This article is free for everyone, thanks to Medium Members. For more information on the novel coronavirus and Covid-19, visit cdc.gov.","markups":[{"start":45,"end":59,"href":"https:\u002F\u002Fmedium.com\u002Fmembership"},{"start":127,"end":134,"href":"https:\u002F\u002Fwww.cdc.gov\u002Fcoronavirus\u002F2019-nCoV"}]}},"COVID_BANNER_POST_ID_OVERRIDE_WHITELIST":["3b31a67bff4a"]},"sharedVoteMessaging":{"TAGS":["politics","election-2020","government","us-politics","election","2020-presidential-race","trump","donald-trump","democrats","republicans","congress","republican-party","democratic-party","biden","joe-biden","maga"],"TOPICS":["politics","election"],"MESSAGE":{"text":"Find out more about the U.S. election results here.","markups":[{"start":46,"end":50,"href":"https:\u002F\u002Fcookpolitical.com\u002F2020-national-popular-vote-tracker"}]},"EXCLUDE_POSTS":["397ef29e3ca5"]},"embedPostRules":[],"recircOptions":{"v1":{"limit":3},"v2":{"limit":8}},"braintreeClientKey":"production_zjkj96jm_m56f8fqpf7ngnrd4","braintree":{"enabled":true,"merchantId":"m56f8fqpf7ngnrd4","merchantAccountId":{"usd":"AMediumCorporation_instant","eur":"amediumcorporation_EUR","cad":"amediumcorporation_CAD"},"publicKey":"ds2nn34bg2z7j5gd","braintreeEnvironment":"production","dashboardUrl":"https:\u002F\u002Fwww.braintreegateway.com\u002Fmerchants","gracePeriodDurationInDays":14,"mediumMembershipPlanId":{"monthly":"ce105f8c57a3","monthlyV2":"e8a5e126-792b-4ee6-8fba-d574c1b02fc5","monthlyWithTrial":"d5ee3dbe3db8","monthlyPremium":"fa741a9b47a2","yearly":"a40ad4a43185","yearlyV2":"3815d7d6-b8ca-4224-9b8c-182f9047866e","yearlyStaff":"d74fb811198a","yearlyWithTrial":"b3bc7350e5c7","yearlyPremium":"e21bd2c12166","monthlyOneYearFree":"e6c0637a-2bad-4171-ab4f-3c268633d83c","monthly25PercentOffFirstYear":"235ecc62-0cdb-49ae-9378-726cd21c504b","monthly20PercentOffFirstYear":"ba518864-9c13-4a99-91ca-411bf0cac756","monthly15PercentOffFirstYear":"594c029b-9f89-43d5-88f8-8173af4e070e","monthly10PercentOffFirstYear":"c6c7bc9a-40f2-4b51-8126-e28511d5bdb0","monthlyForStudents":"629ebe51-da7d-41fd-8293-34cd2f2030a8","yearlyOneYearFree":"78ba7be9-0d9f-4ece-aa3e-b54b826f2bf1","yearly25PercentOffFirstYear":"2dbb010d-bb8f-4eeb-ad5c-a08509f42d34","yearly20PercentOffFirstYear":"47565488-435b-47f8-bf93-40d5fbe0ebc8","yearly15PercentOffFirstYear":"8259809b-0881-47d9-acf7-6c001c7f720f","yearly10PercentOffFirstYear":"9dd694fb-96e1-472c-8d9e-3c868d5c1506","yearlyForStudents":"e29345ef-ab1c-4234-95c5-70e50fe6bc23","monthlyCad":"p52orjkaceei","yearlyCad":"h4q9g2up9ktt"},"braintreeDiscountId":{"oneMonthFree":"MONTHS_FREE_01","threeMonthsFree":"MONTHS_FREE_03","sixMonthsFree":"MONTHS_FREE_06","fiftyPercentOffOneYear":"FIFTY_PERCENT_OFF_ONE_YEAR"},"3DSecureVersion":"2","defaultCurrency":"usd","providerPlanIdCurrency":{"4ycw":"usd","rz3b":"usd","3kqm":"usd","jzw6":"usd","c2q2":"usd","nnsw":"usd","q8qw":"usd","d9y6":"usd","fx7w":"cad","nwf2":"cad"}},"paypalClientId":"AXj1G4fotC2GE8KzWX9mSxCH1wmPE3nJglf4Z2ig_amnhvlMVX87otaq58niAg9iuLktVNF_1WCMnN7v","paypal":{"host":"https:\u002F\u002Fapi.paypal.com:443","clientMode":"production","serverMode":"live","webhookId":"4G466076A0294510S","monthlyPlan":{"planId":"P-9WR0658853113943TMU5FDQA","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlan":{"planId":"P-7N8963881P8875835MU5JOPQ","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oneYearGift":{"name":"Medium Membership (1 Year, Digital Gift Code)","description":"Unlimited access to the best and brightest stories on Medium. Gift codes can be redeemed at medium.com\u002Fredeem.","price":"50.00","currency":"USD","sku":"membership-gift-1-yr"},"oldMonthlyPlan":{"planId":"P-96U02458LM656772MJZUVH2Y","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlan":{"planId":"P-59P80963JF186412JJZU3SMI","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"monthlyPlanWithTrial":{"planId":"P-66C21969LR178604GJPVKUKY","name":"Medium Membership (Monthly) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"yearlyPlanWithTrial":{"planId":"P-6XW32684EX226940VKCT2MFA","name":"Medium Membership (Annual) with setup fee","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"oldMonthlyPlanNoSetupFee":{"planId":"P-4N046520HR188054PCJC7LJI","name":"Medium Membership (Monthly)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed monthly."},"oldYearlyPlanNoSetupFee":{"planId":"P-7A4913502Y5181304CJEJMXQ","name":"Medium Membership (Annual)","description":"Unlimited access to the best and brightest stories on Medium. Membership billed annually."},"sdkUrl":"https:\u002F\u002Fwww.paypal.com\u002Fsdk\u002Fjs"},"stripePublishableKey":"pk_live_7FReX44VnNIInZwrIIx6ghjl","log":{"json":true,"level":"info"},"imageUploadMaxSizeMb":25,"staffPicks":{"title":"Staff Picks","catalogId":"c7bc6e1ee00f"}},"session":{"xsrf":""}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY":{"__typename":"Query","viewer":null,"collectionByDomainOrSlug({\"domainOrSlug\":\"towardsdatascience.com\"})":{"__ref":"Collection:7f60cf5620c9"},"postResult({\"id\":\"7b74f20f3442\"})":{"__ref":"Post:7b74f20f3442"}},"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png":{"__typename":"ImageMetadata","id":"1*VzTUkfeGymHP4Bvav-T-lA.png"},"Collection:7f60cf5620c9":{"__typename":"Collection","id":"7f60cf5620c9","favicon":{"__ref":"ImageMetadata:1*VzTUkfeGymHP4Bvav-T-lA.png"},"customStyleSheet":null,"colorPalette":{"__typename":"ColorPalette","highlightSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FFEDF4FC","point":0},{"__typename":"ColorPoint","color":"#FFE9F2FD","point":0.1},{"__typename":"ColorPoint","color":"#FFE6F1FD","point":0.2},{"__typename":"ColorPoint","color":"#FFE2EFFD","point":0.3},{"__typename":"ColorPoint","color":"#FFDFEEFD","point":0.4},{"__typename":"ColorPoint","color":"#FFDBECFE","point":0.5},{"__typename":"ColorPoint","color":"#FFD7EBFE","point":0.6},{"__typename":"ColorPoint","color":"#FFD4E9FE","point":0.7},{"__typename":"ColorPoint","color":"#FFD0E7FF","point":0.8},{"__typename":"ColorPoint","color":"#FFCCE6FF","point":0.9},{"__typename":"ColorPoint","color":"#FFC8E4FF","point":1}]},"defaultBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FFFFFFFF","colorPoints":[{"__typename":"ColorPoint","color":"#FF668AAA","point":0},{"__typename":"ColorPoint","color":"#FF61809D","point":0.1},{"__typename":"ColorPoint","color":"#FF5A7690","point":0.2},{"__typename":"ColorPoint","color":"#FF546C83","point":0.3},{"__typename":"ColorPoint","color":"#FF4D6275","point":0.4},{"__typename":"ColorPoint","color":"#FF455768","point":0.5},{"__typename":"ColorPoint","color":"#FF3D4C5A","point":0.6},{"__typename":"ColorPoint","color":"#FF34414C","point":0.7},{"__typename":"ColorPoint","color":"#FF2B353E","point":0.8},{"__typename":"ColorPoint","color":"#FF21282F","point":0.9},{"__typename":"ColorPoint","color":"#FF161B1F","point":1}]},"tintBackgroundSpectrum":{"__typename":"ColorSpectrum","backgroundColor":"#FF355876","colorPoints":[{"__typename":"ColorPoint","color":"#FF355876","point":0},{"__typename":"ColorPoint","color":"#FF4D6C88","point":0.1},{"__typename":"ColorPoint","color":"#FF637F99","point":0.2},{"__typename":"ColorPoint","color":"#FF7791A8","point":0.3},{"__typename":"ColorPoint","color":"#FF8CA2B7","point":0.4},{"__typename":"ColorPoint","color":"#FF9FB3C6","point":0.5},{"__typename":"ColorPoint","color":"#FFB2C3D4","point":0.6},{"__typename":"ColorPoint","color":"#FFC5D2E1","point":0.7},{"__typename":"ColorPoint","color":"#FFD7E2EE","point":0.8},{"__typename":"ColorPoint","color":"#FFE9F1FA","point":0.9},{"__typename":"ColorPoint","color":"#FFFBFFFF","point":1}]}},"googleAnalyticsId":null,"editors":[{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:7e12c71dfa81"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:e6ad8abedec9"}},{"__typename":"CollectionMastheadUserItem","user":{"__ref":"User:895063a310f4"}}],"name":"Towards Data Science","avatar":{"__ref":"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg"},"domain":"towardsdatascience.com","slug":"towards-data-science","description":"Your home for data science. A Medium publication sharing concepts, ideas and codes.","subscriberCount":713394,"viewerEdge":{"__ref":"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_7359861dcfbb"},"twitterUsername":"TDataScience","facebookPageId":null,"logo":{"__ref":"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png"}},"User:7e12c71dfa81":{"__typename":"User","id":"7e12c71dfa81"},"User:e6ad8abedec9":{"__typename":"User","id":"e6ad8abedec9"},"User:895063a310f4":{"__typename":"User","id":"895063a310f4"},"ImageMetadata:1*CJe3891yB1A1mzMdqemkdg.jpeg":{"__typename":"ImageMetadata","id":"1*CJe3891yB1A1mzMdqemkdg.jpeg"},"LinkedAccounts:46bbd28ad0a":{"__typename":"LinkedAccounts","mastodon":null,"id":"46bbd28ad0a"},"UserViewerEdge:userId:46bbd28ad0a-viewerId:lo_7359861dcfbb":{"__typename":"UserViewerEdge","id":"userId:46bbd28ad0a-viewerId:lo_7359861dcfbb","isFollowing":false,"isUser":false,"isMuting":false},"NewsletterV3:e54576fe18a":{"__typename":"NewsletterV3","id":"e54576fe18a","type":"NEWSLETTER_TYPE_AUTHOR","slug":"46bbd28ad0a","name":"46bbd28ad0a","collection":null,"user":{"__ref":"User:46bbd28ad0a"}},"User:46bbd28ad0a":{"__typename":"User","id":"46bbd28ad0a","name":"Mihir Garimella","username":"mihirg343","newsletterV3":{"__ref":"NewsletterV3:e54576fe18a"},"linkedAccounts":{"__ref":"LinkedAccounts:46bbd28ad0a"},"isSuspended":false,"imageId":"1*FsTbICEiyEbhog5a_EbQkQ.jpeg","mediumMemberAt":0,"verifications":{"__typename":"VerifiedInfo","isBookAuthor":false},"socialStats":{"__typename":"SocialStats","followerCount":32},"customDomainState":null,"hasSubdomain":false,"bio":"","isPartnerProgramEnrolled":false,"viewerEdge":{"__ref":"UserViewerEdge:userId:46bbd28ad0a-viewerId:lo_7359861dcfbb"},"viewerIsUser":false,"postSubscribeMembershipUpsellShownAt":0,"allowNotes":true,"twitterScreenName":"","membership":null},"Topic:ae5d4995e225":{"__typename":"Topic","slug":"data-science","id":"ae5d4995e225","name":"Data Science"},"Paragraph:f5a07a5288db_0":{"__typename":"Paragraph","id":"f5a07a5288db_0","name":"1070","type":"H3","href":null,"layout":null,"metadata":null,"text":"Sign Language Recognition with Advanced Computer Vision","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_1":{"__typename":"Paragraph","id":"f5a07a5288db_1","name":"a5ac","type":"H4","href":null,"layout":null,"metadata":null,"text":"Detecting Sign Language Characters in Real Time Using MediaPipe and Keras","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*Iv-GIxB6KwJpZPaQ":{"__typename":"ImageMetadata","id":"0*Iv-GIxB6KwJpZPaQ","originalHeight":481,"originalWidth":721,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_2":{"__typename":"Paragraph","id":"f5a07a5288db_2","name":"20bd","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*Iv-GIxB6KwJpZPaQ"},"text":"Image of Sign Language ‘F’ from Pexels","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_3":{"__typename":"Paragraph","id":"f5a07a5288db_3","name":"95d0","type":"P","href":null,"layout":null,"metadata":null,"text":"Sign Language is a form of communication used primarily by people hard of hearing or deaf. This type of gesture-based language allows people to convey ideas and thoughts easily overcoming the barriers caused by difficulties from hearing issues.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_4":{"__typename":"Paragraph","id":"f5a07a5288db_4","name":"6412","type":"P","href":null,"layout":null,"metadata":null,"text":"A major issue with this convenient form of communication is the lack of knowledge of the language for the vast majority of the global population. Just as any other language, learning Sign Language takes much time and effort, discouraging to from being learned by the larger population.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_5":{"__typename":"Paragraph","id":"f5a07a5288db_5","name":"2444","type":"P","href":null,"layout":null,"metadata":null,"text":"However, an evident solution to this issue is present in the world of Machine Learning and Image Detection. Implementing predictive model technology to automatically classify Sign Language symbols can be used to create a form of real-time captioning for virtual conferences like Zoom meetings and other such things. This would greatly increase access of such services to those with hearing impairments as it would go hand-in-hand with voice-based captioning, creating a two-way communication system online for people with hearing issues.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_6":{"__typename":"Paragraph","id":"f5a07a5288db_6","name":"fe57","type":"P","href":null,"layout":null,"metadata":null,"text":"Many large training datasets for Sign Language are available on Kaggle, a popular resource for data science. The one used in this model is called “Sign Language MNIST” and is a public-domain free-to-use dataset with pixel information for around 1,000 images of each of 24 ASL Letters, excluding J and Z as they are gesture-based signs.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":147,"end":166,"href":"https:\u002F\u002Fwww.kaggle.com\u002Fdatasets\u002Fdatamunge\u002Fsign-language-mnist","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":146,"end":167,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":146,"end":167,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*EC2QFI9soQV-qMlY":{"__typename":"ImageMetadata","id":"0*EC2QFI9soQV-qMlY","originalHeight":471,"originalWidth":665,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_7":{"__typename":"Paragraph","id":"f5a07a5288db_7","name":"54f4","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*EC2QFI9soQV-qMlY"},"text":"“Cropped image montage panel of various users and backgrounds for American Sign Language letters” from Sign Language MNIST","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_8":{"__typename":"Paragraph","id":"f5a07a5288db_8","name":"a9e7","type":"P","href":null,"layout":null,"metadata":null,"text":"The first step of preparing the data for training is to convert and shape all of the pixel data from the dataset into images so they can be read by the algorithm.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:def872e77d8fc1f74fb3847958282184":{"__typename":"MediaResource","id":"def872e77d8fc1f74fb3847958282184","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"model.py"},"Paragraph:f5a07a5288db_9":{"__typename":"Paragraph","id":"f5a07a5288db_9","name":"2daf","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:def872e77d8fc1f74fb3847958282184"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_10":{"__typename":"Paragraph","id":"f5a07a5288db_10","name":"bb1b","type":"P","href":null,"layout":null,"metadata":null,"text":"The code above starts by reshaping all of the MNIST training image files so the model understands the input files. Along with this, the LabelBinarizer() variable takes the classes in the dataset and converts them to binary, a process that greatly speeds up the training of the model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_11":{"__typename":"Paragraph","id":"f5a07a5288db_11","name":"ab32","type":"P","href":null,"layout":null,"metadata":null,"text":"The next step is to create the data generator to randomly implement changes to the data, increasing the amount of training examples and making the images more realistic by adding noise and transformations to different instances.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:bf2c786f2b758ced89c691553226753f":{"__typename":"MediaResource","id":"bf2c786f2b758ced89c691553226753f","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"model.py"},"Paragraph:f5a07a5288db_12":{"__typename":"Paragraph","id":"f5a07a5288db_12","name":"78ab","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:bf2c786f2b758ced89c691553226753f"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_13":{"__typename":"Paragraph","id":"f5a07a5288db_13","name":"9d98","type":"P","href":null,"layout":null,"metadata":null,"text":"After processing the images, the CNN model must be compiled to recognize all of the classes of information being used in the data, namely the 24 different groups of images. Normalization of the data must also be added to the data, equally balancing the classes with less images.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:f0617605b23b010debfff855484ad275":{"__typename":"MediaResource","id":"f0617605b23b010debfff855484ad275","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"model.py"},"Paragraph:f5a07a5288db_14":{"__typename":"Paragraph","id":"f5a07a5288db_14","name":"8478","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:f0617605b23b010debfff855484ad275"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_15":{"__typename":"Paragraph","id":"f5a07a5288db_15","name":"ff41","type":"P","href":null,"layout":null,"metadata":null,"text":"Notice the initialization of the algorithm with the adding of variables such as the Conv2D model, and the condensing to 24 features. We also use batching techniques to allow the CNN to handle the data more efficiently.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_16":{"__typename":"Paragraph","id":"f5a07a5288db_16","name":"8e06","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, defining the loss functions and metrics along with fitting the model to the data will create our Sign Language Recognition system. It is important to recognize the model.save() command at the end of the statement due to the length of time required to build the model. Re-training the model for every use can take hours of time.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":173,"end":185,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":173,"end":185,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:d64a528c541f0e717957e054cb7aa601":{"__typename":"MediaResource","id":"d64a528c541f0e717957e054cb7aa601","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"model.py"},"Paragraph:f5a07a5288db_17":{"__typename":"Paragraph","id":"f5a07a5288db_17","name":"14fc","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:d64a528c541f0e717957e054cb7aa601"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_18":{"__typename":"Paragraph","id":"f5a07a5288db_18","name":"6f2a","type":"P","href":null,"layout":null,"metadata":null,"text":"This code has a lot to unpack. Let’s look at it in sections.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_19":{"__typename":"Paragraph","id":"f5a07a5288db_19","name":"0b19","type":"P","href":null,"layout":null,"metadata":null,"text":"Line 1:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_20":{"__typename":"Paragraph","id":"f5a07a5288db_20","name":"de06","type":"P","href":null,"layout":null,"metadata":null,"text":"The model.compile() function takes many parameters, of which three are displayed in the code. The optimizer and loss parameters work together along with the epoch statement in the next line to efficiently reduce the amount of error in the model by incrementally changing computation methods on the data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":4,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":4,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_21":{"__typename":"Paragraph","id":"f5a07a5288db_21","name":"57b5","type":"P","href":null,"layout":null,"metadata":null,"text":"Along with this, the metric of choice to be optimized is the accuracy functions, which ensures that the model will have the maximum accuracy achievable after the set number of epochs.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_22":{"__typename":"Paragraph","id":"f5a07a5288db_22","name":"6506","type":"P","href":null,"layout":null,"metadata":null,"text":"Line 4:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_23":{"__typename":"Paragraph","id":"f5a07a5288db_23","name":"73ff","type":"P","href":null,"layout":null,"metadata":null,"text":"The function run here fits the designed model to the data from the image data developed in the first bit of code. It also defines the number of epochs or iterations the model has to enhance the accuracy of the image detection. The validation set is also called here, to introduce a testing aspect to the model. The model calculates the accuracy using this data.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":144,"end":151,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":144,"end":151,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_24":{"__typename":"Paragraph","id":"f5a07a5288db_24","name":"09c4","type":"P","href":null,"layout":null,"metadata":null,"text":"Line 5:","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_25":{"__typename":"Paragraph","id":"f5a07a5288db_25","name":"89aa","type":"P","href":null,"layout":null,"metadata":null,"text":"Of all of the statements in the code bit, the model.save() function may be the most important part of this code, as it can potentially save hours of time when implementing the model.","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"STRONG","start":46,"end":58,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":46,"end":58,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*yu75uOn-N8EFoXBd":{"__typename":"ImageMetadata","id":"0*yu75uOn-N8EFoXBd","originalHeight":480,"originalWidth":721,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_26":{"__typename":"Paragraph","id":"f5a07a5288db_26","name":"150f","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*yu75uOn-N8EFoXBd"},"text":"Image of Sign Language ‘X’ from Pexels","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_27":{"__typename":"Paragraph","id":"f5a07a5288db_27","name":"572f","type":"P","href":null,"layout":null,"metadata":null,"text":"The model developed accurately detects and classifies Sign Language symbols with about 95% training accuracy.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_28":{"__typename":"Paragraph","id":"f5a07a5288db_28","name":"4f45","type":"P","href":null,"layout":null,"metadata":null,"text":"Now, using two popular live video processing libraries known as Mediapipe and Open-CV, we can take webcam input and run our previously developed model on real time video stream.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*HN0e1ezZ5R5ifqpF":{"__typename":"ImageMetadata","id":"0*HN0e1ezZ5R5ifqpF","originalHeight":480,"originalWidth":721,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_29":{"__typename":"Paragraph","id":"f5a07a5288db_29","name":"113d","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*HN0e1ezZ5R5ifqpF"},"text":"Image of Woman Showing Sign Language from Pexels","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_30":{"__typename":"Paragraph","id":"f5a07a5288db_30","name":"6720","type":"P","href":null,"layout":null,"metadata":null,"text":"To start, we need to import the required packages for the program.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:c698083c49fdfd70e15f39c78cd7c984":{"__typename":"MediaResource","id":"c698083c49fdfd70e15f39c78cd7c984","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"camerahands.py"},"Paragraph:f5a07a5288db_31":{"__typename":"Paragraph","id":"f5a07a5288db_31","name":"c69d","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:c698083c49fdfd70e15f39c78cd7c984"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_32":{"__typename":"Paragraph","id":"f5a07a5288db_32","name":"e7d3","type":"P","href":null,"layout":null,"metadata":null,"text":"The OS command run at the beginning simply blocks unnecessary warnings from the Tensorflow library used by Mediapipe. This makes the future output provided by the program clearer to understand.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_33":{"__typename":"Paragraph","id":"f5a07a5288db_33","name":"62e6","type":"P","href":null,"layout":null,"metadata":null,"text":"Before we initiate the main while loop of the code, we need to first define some variables such as the saved model and information on the camera for Open-CV.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:d80ed916d57fdf97d2cc4ce51665c451":{"__typename":"MediaResource","id":"d80ed916d57fdf97d2cc4ce51665c451","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"camerahands.py"},"Paragraph:f5a07a5288db_34":{"__typename":"Paragraph","id":"f5a07a5288db_34","name":"ccff","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:d80ed916d57fdf97d2cc4ce51665c451"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_35":{"__typename":"Paragraph","id":"f5a07a5288db_35","name":"bc1f","type":"P","href":null,"layout":null,"metadata":null,"text":"Each of the variables set here are grouped into one of four categories. The category at the beginning pertains directly to the model that we trained in the first part of this paper. The second and third sections of the code define variables required to run and start Mediapipe and Open-CV. The final category is used primarily to analyze the frame when detected, and create the dictionary used in the cross-referencing of the data provided by the image model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_36":{"__typename":"Paragraph","id":"f5a07a5288db_36","name":"b796","type":"P","href":null,"layout":null,"metadata":null,"text":"The next part to this program is the main while True loop in which much of the program runs in.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:ac55839b61904d0c5d392a7d572a0b04":{"__typename":"MediaResource","id":"ac55839b61904d0c5d392a7d572a0b04","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"camerahands.py"},"Paragraph:f5a07a5288db_37":{"__typename":"Paragraph","id":"f5a07a5288db_37","name":"c686","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:ac55839b61904d0c5d392a7d572a0b04"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_38":{"__typename":"Paragraph","id":"f5a07a5288db_38","name":"d049","type":"P","href":null,"layout":null,"metadata":null,"text":"This section of the program takes the input from your camera and uses our imported image processing library to display the input from the device to the computer. This portion of code focuses on getting general information from your camera and simply showing it back in a new window. However, using the Mediapipe library, we can detect the major landmarks of the hand such as the fingers and palms, and create a bounding box around the hand.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*6aEBXcTf3YxIOund.png":{"__typename":"ImageMetadata","id":"0*6aEBXcTf3YxIOund.png","originalHeight":354,"originalWidth":337,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_39":{"__typename":"Paragraph","id":"f5a07a5288db_39","name":"a934","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*6aEBXcTf3YxIOund.png"},"text":"Image of Hand Annotations from Mediapipe, by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_40":{"__typename":"Paragraph","id":"f5a07a5288db_40","name":"9599","type":"P","href":null,"layout":null,"metadata":null,"text":"The idea of a bounding box is a crucial component to all forms of image classification and analysis. The box allows the model to focus directly on the portion of the image needed for the function. Without this, the algorithm finds patterns in wrong places and can cause an incorrect result.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_41":{"__typename":"Paragraph","id":"f5a07a5288db_41","name":"1d45","type":"P","href":null,"layout":null,"metadata":null,"text":"For instance, during the training process, the lack of a bounding box can lead to the model correlating features of an image such as a clock, or a chair, to a label. This may cause the program to notice the clock located in the image and decide what Sign Language character is being shown solely on the fact that a clock is present.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*ngWT2fByrbzrHpkG.jpeg":{"__typename":"ImageMetadata","id":"0*ngWT2fByrbzrHpkG.jpeg","originalHeight":525,"originalWidth":500,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_42":{"__typename":"Paragraph","id":"f5a07a5288db_42","name":"341c","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*ngWT2fByrbzrHpkG.jpeg"},"text":"Previous Image with a highlighted clock, by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_43":{"__typename":"Paragraph","id":"f5a07a5288db_43","name":"3ccf","type":"P","href":null,"layout":null,"metadata":null,"text":"Almost done! The second to last part of the program is capturing a single frame on cue, cropping it to the dimensions of the bounding box.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:58aad4104d0c7d491366c365d462a233":{"__typename":"MediaResource","id":"58aad4104d0c7d491366c365d462a233","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"camerahands.py"},"Paragraph:f5a07a5288db_44":{"__typename":"Paragraph","id":"f5a07a5288db_44","name":"cd9d","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:58aad4104d0c7d491366c365d462a233"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_45":{"__typename":"Paragraph","id":"f5a07a5288db_45","name":"0b5b","type":"P","href":null,"layout":null,"metadata":null,"text":"This code looks very similar to the last portion of the program. This is due mainly to the fact that the process involving the production of the bounding box is the same in both parts. However, in this analysis section of the code, we make use of the image reshaping feature from Open-CV to resize the image to the dimensions of the bounding box, rather than creating a visual object around it. Along with this, we also use NumPy and Open-CV to modify the image to have the same characteristics as the images the model was trained on. We also use pandas to create a dataframe with the pixel data from the images saved, so we can normalize the data in the same way we did for the model creation.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*S0zOudPJ2C6-GMny.png":{"__typename":"ImageMetadata","id":"0*S0zOudPJ2C6-GMny.png","originalHeight":488,"originalWidth":450,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_46":{"__typename":"Paragraph","id":"f5a07a5288db_46","name":"42f2","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*S0zOudPJ2C6-GMny.png"},"text":"Modified Image of Hand, by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_47":{"__typename":"Paragraph","id":"f5a07a5288db_47","name":"6528","type":"P","href":null,"layout":null,"metadata":null,"text":"Towards the top of the code, you may notice the odd sequence of variables being defined. This is due to the nature of the camera library syntax. When an image is processed and changed by Open-CV, the changes are made on top of the frame used, essentially saving the changes made to the image. The definition of multiple variables of equal value makes it so that the frame displayed in by the function is separate from the picture on which the model is being ran on.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_48":{"__typename":"Paragraph","id":"f5a07a5288db_48","name":"733c","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, we need to run the trained model on the processed image and process the information output.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"MediaResource:65bcec52d451c7e45340b72e08c3d4f7":{"__typename":"MediaResource","id":"65bcec52d451c7e45340b72e08c3d4f7","iframeSrc":"","iframeHeight":0,"iframeWidth":0,"title":"camerahands.py"},"Paragraph:f5a07a5288db_49":{"__typename":"Paragraph","id":"f5a07a5288db_49","name":"63d6","type":"IFRAME","href":null,"layout":"INSET_CENTER","metadata":null,"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":{"__typename":"Iframe","mediaResource":{"__ref":"MediaResource:65bcec52d451c7e45340b72e08c3d4f7"}},"mixtapeMetadata":null},"Paragraph:f5a07a5288db_50":{"__typename":"Paragraph","id":"f5a07a5288db_50","name":"2eca","type":"P","href":null,"layout":null,"metadata":null,"text":"There is a lot of information being run through this section of the code. We will dissect this part of the code one by one.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_51":{"__typename":"Paragraph","id":"f5a07a5288db_51","name":"e050","type":"P","href":null,"layout":null,"metadata":null,"text":"The first two lines draw the predicted probabilities that a hand image is any of the different classes from Keras. The data is presented in the form of 2 tensors, of which, the first tensor contains information on the probabilities. A tensor is essentially a collection of feature vectors, very similar to an array. The tensor produced by the model is one dimensional, allowing it to be used with the linear algebra library NumPy to parse the information into a more pythonic form.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_52":{"__typename":"Paragraph","id":"f5a07a5288db_52","name":"e8af","type":"P","href":null,"layout":null,"metadata":null,"text":"From here, we utilize the previously created list of classes under the variable letterpred to create a dictionary, matching the values from the tensor to the keys. This allows us to match each character’s probability with the class it corresponds to.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_53":{"__typename":"Paragraph","id":"f5a07a5288db_53","name":"dfb5","type":"P","href":null,"layout":null,"metadata":null,"text":"Following this step, we use list comprehension to order and sort the values from highest to lowest. This then allows us to take the first few items in the list and designate them the 3 characters that closest correspond to the Sign Language image shown.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_54":{"__typename":"Paragraph","id":"f5a07a5288db_54","name":"d25c","type":"P","href":null,"layout":null,"metadata":null,"text":"Finally, we use a for loop to cycle through all of the key:value pairs in the dictionary created to match the highest values to their corresponding keys and print out the output with each character’ probability.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:0*IdEh9O6q4QpYi9va.png":{"__typename":"ImageMetadata","id":"0*IdEh9O6q4QpYi9va.png","originalHeight":514,"originalWidth":500,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_55":{"__typename":"Paragraph","id":"f5a07a5288db_55","name":"e3d8","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:0*IdEh9O6q4QpYi9va.png"},"text":"Sign Language ‘A’, by Author","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*0yoN0UZXpkeukPIC3_rXlQ.png":{"__typename":"ImageMetadata","id":"1*0yoN0UZXpkeukPIC3_rXlQ.png","originalHeight":130,"originalWidth":387,"focusPercentX":null,"focusPercentY":null,"alt":null},"Paragraph:f5a07a5288db_56":{"__typename":"Paragraph","id":"f5a07a5288db_56","name":"01f3","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"__ref":"ImageMetadata:1*0yoN0UZXpkeukPIC3_rXlQ.png"},"text":"","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_57":{"__typename":"Paragraph","id":"f5a07a5288db_57","name":"940b","type":"P","href":null,"layout":null,"metadata":null,"text":"As shown, the model accurately predicts the character being shown from the camera. Along with the Predicted Character, the program also displays the confidence of the classification from the CNN Keras model.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_58":{"__typename":"Paragraph","id":"f5a07a5288db_58","name":"ef69","type":"P","href":null,"layout":null,"metadata":null,"text":"The model developed can be implemented in various ways, with the main use being a captioning device for calls involving video communication like Facetime. To create such an application, the model would have to be running frame-by-frame, predicting what sign is being shown at all times. Using other systems, we can also recognize when an individual is showing no sign, or is transitioning between signs, to more accurately judge the words being shown through ASL. This implementation could be used to string together letters being shown to eventually recognize words and even sentences, creating a fully functioning Sign Language to text translator. Such a device would greatly increase ease-of-access to the benefits of virtual communication for those with hearing imparities.","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_59":{"__typename":"Paragraph","id":"f5a07a5288db_59","name":"052c","type":"P","href":null,"layout":null,"metadata":null,"text":"This program allows for simple and easy communication from Sign Language to English through the use of Keras image analysis models. The code for this project can be found on my GitHub profile, linked below:","hasDropCap":null,"dropCapImage":null,"markups":[],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"Paragraph:f5a07a5288db_60":{"__typename":"Paragraph","id":"f5a07a5288db_60","name":"61bf","type":"P","href":null,"layout":null,"metadata":null,"text":"mg343\u002FSign-Language-Detection (github.com)","hasDropCap":null,"dropCapImage":null,"markups":[{"__typename":"Markup","type":"A","start":0,"end":42,"href":"https:\u002F\u002Fgithub.com\u002Fmg343\u002FSign-Language-Detection","anchorType":"LINK","userId":null,"linkMetadata":null},{"__typename":"Markup","type":"STRONG","start":0,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null},{"__typename":"Markup","type":"EM","start":0,"end":42,"href":null,"anchorType":null,"userId":null,"linkMetadata":null}],"codeBlockMetadata":null,"iframe":null,"mixtapeMetadata":null},"CollectionViewerEdge:collectionId:7f60cf5620c9-viewerId:lo_7359861dcfbb":{"__typename":"CollectionViewerEdge","id":"collectionId:7f60cf5620c9-viewerId:lo_7359861dcfbb","isEditor":false,"isMuting":false},"ImageMetadata:1*cFFKn8rFH4ZndmaYeAs6iQ.png":{"__typename":"ImageMetadata","id":"1*cFFKn8rFH4ZndmaYeAs6iQ.png","originalWidth":2381,"originalHeight":743},"Tag:nlp":{"__typename":"Tag","id":"nlp","displayTitle":"NLP","normalizedTagSlug":"nlp"},"Tag:sign-language":{"__typename":"Tag","id":"sign-language","displayTitle":"Sign Language","normalizedTagSlug":"sign-language"},"Tag:machine-learning":{"__typename":"Tag","id":"machine-learning","displayTitle":"Machine Learning","normalizedTagSlug":"machine-learning"},"Tag:keras":{"__typename":"Tag","id":"keras","displayTitle":"Keras","normalizedTagSlug":"keras"},"Tag:editors-pick":{"__typename":"Tag","id":"editors-pick","displayTitle":"Editors Pick","normalizedTagSlug":"editors-pick"},"Post:7b74f20f3442":{"__typename":"Post","id":"7b74f20f3442","collection":{"__ref":"Collection:7f60cf5620c9"},"content({\"postMeteringOptions\":{}})":{"__typename":"PostContent","isLockedPreviewOnly":false,"bodyModel":{"__typename":"RichText","sections":[{"__typename":"Section","name":"0296","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"d227","startIndex":6,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"a0b9","startIndex":7,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"bd43","startIndex":28,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null},{"__typename":"Section","name":"5d2c","startIndex":58,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null}],"paragraphs":[{"__ref":"Paragraph:f5a07a5288db_0"},{"__ref":"Paragraph:f5a07a5288db_1"},{"__ref":"Paragraph:f5a07a5288db_2"},{"__ref":"Paragraph:f5a07a5288db_3"},{"__ref":"Paragraph:f5a07a5288db_4"},{"__ref":"Paragraph:f5a07a5288db_5"},{"__ref":"Paragraph:f5a07a5288db_6"},{"__ref":"Paragraph:f5a07a5288db_7"},{"__ref":"Paragraph:f5a07a5288db_8"},{"__ref":"Paragraph:f5a07a5288db_9"},{"__ref":"Paragraph:f5a07a5288db_10"},{"__ref":"Paragraph:f5a07a5288db_11"},{"__ref":"Paragraph:f5a07a5288db_12"},{"__ref":"Paragraph:f5a07a5288db_13"},{"__ref":"Paragraph:f5a07a5288db_14"},{"__ref":"Paragraph:f5a07a5288db_15"},{"__ref":"Paragraph:f5a07a5288db_16"},{"__ref":"Paragraph:f5a07a5288db_17"},{"__ref":"Paragraph:f5a07a5288db_18"},{"__ref":"Paragraph:f5a07a5288db_19"},{"__ref":"Paragraph:f5a07a5288db_20"},{"__ref":"Paragraph:f5a07a5288db_21"},{"__ref":"Paragraph:f5a07a5288db_22"},{"__ref":"Paragraph:f5a07a5288db_23"},{"__ref":"Paragraph:f5a07a5288db_24"},{"__ref":"Paragraph:f5a07a5288db_25"},{"__ref":"Paragraph:f5a07a5288db_26"},{"__ref":"Paragraph:f5a07a5288db_27"},{"__ref":"Paragraph:f5a07a5288db_28"},{"__ref":"Paragraph:f5a07a5288db_29"},{"__ref":"Paragraph:f5a07a5288db_30"},{"__ref":"Paragraph:f5a07a5288db_31"},{"__ref":"Paragraph:f5a07a5288db_32"},{"__ref":"Paragraph:f5a07a5288db_33"},{"__ref":"Paragraph:f5a07a5288db_34"},{"__ref":"Paragraph:f5a07a5288db_35"},{"__ref":"Paragraph:f5a07a5288db_36"},{"__ref":"Paragraph:f5a07a5288db_37"},{"__ref":"Paragraph:f5a07a5288db_38"},{"__ref":"Paragraph:f5a07a5288db_39"},{"__ref":"Paragraph:f5a07a5288db_40"},{"__ref":"Paragraph:f5a07a5288db_41"},{"__ref":"Paragraph:f5a07a5288db_42"},{"__ref":"Paragraph:f5a07a5288db_43"},{"__ref":"Paragraph:f5a07a5288db_44"},{"__ref":"Paragraph:f5a07a5288db_45"},{"__ref":"Paragraph:f5a07a5288db_46"},{"__ref":"Paragraph:f5a07a5288db_47"},{"__ref":"Paragraph:f5a07a5288db_48"},{"__ref":"Paragraph:f5a07a5288db_49"},{"__ref":"Paragraph:f5a07a5288db_50"},{"__ref":"Paragraph:f5a07a5288db_51"},{"__ref":"Paragraph:f5a07a5288db_52"},{"__ref":"Paragraph:f5a07a5288db_53"},{"__ref":"Paragraph:f5a07a5288db_54"},{"__ref":"Paragraph:f5a07a5288db_55"},{"__ref":"Paragraph:f5a07a5288db_56"},{"__ref":"Paragraph:f5a07a5288db_57"},{"__ref":"Paragraph:f5a07a5288db_58"},{"__ref":"Paragraph:f5a07a5288db_59"},{"__ref":"Paragraph:f5a07a5288db_60"}]},"validatedShareKey":"","shareKeyCreator":null},"creator":{"__ref":"User:46bbd28ad0a"},"inResponseToEntityType":null,"isLocked":false,"isMarkedPaywallOnly":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fsign-language-recognition-with-advanced-computer-vision-7b74f20f3442","primaryTopic":{"__ref":"Topic:ae5d4995e225"},"topics":[{"__typename":"Topic","slug":"machine-learning"},{"__typename":"Topic","slug":"data-science"}],"isPublished":true,"latestPublishedVersion":"f5a07a5288db","visibility":"PUBLIC","postResponses":{"__typename":"PostResponses","count":2},"clapCount":96,"allowResponses":true,"isLimitedState":false,"title":"Sign Language Recognition with Advanced Computer Vision","isSeries":false,"sequence":null,"uniqueSlug":"sign-language-recognition-with-advanced-computer-vision-7b74f20f3442","socialTitle":"","socialDek":"","noIndex":null,"canonicalUrl":"","metaDescription":"","latestPublishedAt":1661268974716,"readingTime":7.996226415094339,"previewContent":{"__typename":"PreviewContent","subtitle":"Detecting Sign Language Characters in Real Time Using MediaPipe and Keras"},"previewImage":{"__ref":"ImageMetadata:0*6aEBXcTf3YxIOund.png"},"isShortform":false,"seoTitle":"","firstPublishedAt":1661268974716,"updatedAt":1670174399795,"shortformType":"SHORTFORM_TYPE_LINK","seoDescription":"","isSuspended":false,"license":"ALL_RIGHTS_RESERVED","tags":[{"__ref":"Tag:nlp"},{"__ref":"Tag:sign-language"},{"__ref":"Tag:machine-learning"},{"__ref":"Tag:keras"},{"__ref":"Tag:editors-pick"}],"isNewsletter":false,"statusForCollection":"APPROVED","pendingCollection":null,"detectedLanguage":"en","wordCount":1801,"layerCake":3}}</script><script>window.__MIDDLEWARE_STATE__={"session":{"xsrf":""},"cache":{"cacheStatus":"HIT"}}</script><script src="https://cdn-client.medium.com/lite/static/js/manifest.fbff5f0d.js"></script><script src="https://cdn-client.medium.com/lite/static/js/3905.cfd85a7e.js"></script><script src="https://cdn-client.medium.com/lite/static/js/main.6ee53b82.js"></script><script src="https://cdn-client.medium.com/lite/static/js/instrumentation.d9108df7.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/reporting.ff22a7a5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9120.5df29668.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3171.5b0ceee8.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4810.988332a1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6618.db187378.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/1386.e126dec1.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/9977.343f5002.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5250.fc15c18c.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/8261.08d8d6be.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/7975.19e89f16.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2648.a582e725.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2712.0f6c85f5.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2793.01d2b056.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6636.ef641110.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3735.ca2f95e3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5642.b8216689.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6546.0f97e7cb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6834.f2d3924e.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2420.0330d157.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/2106.21ff89d3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6696.92b2dfc3.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/5832.07d4db30.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/3366.16d43002.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/6040.6ceb7f43.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/4391.3e417aeb.chunk.js"></script>
<script src="https://cdn-client.medium.com/lite/static/js/PostPage.MainContent.8a1aec03.chunk.js"></script><script>window.main();</script></body></html>